{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpectralNET Exploring Spatial Spectral Wavelet CNN for Hyper Spectral Image Classification\n",
    "\n",
    "**Authors:** Tanmay CHAKRABORTY and Utkarsh TREHAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "executionInfo": {
     "elapsed": 5572,
     "status": "ok",
     "timestamp": 1602478409232,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "r9imWZNCMoOM",
    "outputId": "e6ddc3e2-53c3-4e29-ceb6-5b303ac0b75b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spectral\n",
      "  Downloading spectral-0.22.1-py3-none-any.whl (212 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\utkarsh trehan\\anaconda3\\envs\\malis\\lib\\site-packages (from spectral) (1.19.2)\n",
      "Installing collected packages: spectral\n",
      "Successfully installed spectral-0.22.1\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, Conv3D, Flatten, Dense, Reshape, BatchNormalization\n",
    "from keras.layers import Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as Kb\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Activation\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.utils import plot_model\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
    " \n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from operator import truediv\n",
    " \n",
    "from plotly.offline import init_notebook_mode\n",
    " \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import os\n",
    "!pip install spectral\n",
    "import spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5565,
     "status": "ok",
     "timestamp": 1602478409233,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "HC83Bv1IPQfc"
   },
   "outputs": [],
   "source": [
    "def applyFA(X, numComponents=75):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    fa = FactorAnalysis(n_components=numComponents, random_state=0)\n",
    "    newX = fa.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "    return newX, fa\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5559,
     "status": "ok",
     "timestamp": 1602478409234,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "UGivdxXN1pCh"
   },
   "outputs": [],
   "source": [
    "# def applyPCA(X, numComponents=75):\n",
    "#     newX = np.reshape(X, (-1, X.shape[2]))\n",
    "#     pca = PCA(n_components=numComponents, whiten=True)\n",
    "#     newX = pca.fit_transform(newX)\n",
    "#     newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "#     return newX, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5555,
     "status": "ok",
     "timestamp": 1602478409235,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "jEBfhIyVNHRQ"
   },
   "outputs": [],
   "source": [
    "## GLOBAL VARIABLES\n",
    "dataset = 'SA'\n",
    "test_ratio = 0.9\n",
    "windowSize = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 5550,
     "status": "ok",
     "timestamp": 1602478409236,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "7wXNSkhfM3gs"
   },
   "outputs": [],
   "source": [
    "def loadData(name):\n",
    "    data_path = os.path.join(os.getcwd(),'data')\n",
    "    if name == 'IP':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'Indian_pines_corrected.mat'))['indian_pines_corrected']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'Indian_pines_gt.mat'))['indian_pines_gt']\n",
    "    elif name == 'SA':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'Salinas_corrected.mat'))['salinas_corrected']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'Salinas_gt.mat'))['salinas_gt']\n",
    "    elif name == 'PU':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'PaviaU.mat'))['paviaU']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'PaviaU_gt.mat'))['paviaU_gt']\n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 5545,
     "status": "ok",
     "timestamp": 1602478409237,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "iaIzfkQ3NDvS"
   },
   "outputs": [],
   "source": [
    "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState,\n",
    "                                                        stratify=y)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 5538,
     "status": "ok",
     "timestamp": 1602478409237,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "M0he4FtONMU-"
   },
   "outputs": [],
   "source": [
    "def padWithZeros(X, margin=2):\n",
    "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
    "    return newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5533,
     "status": "ok",
     "timestamp": 1602478409238,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "l0wsTkhNNO04"
   },
   "outputs": [],
   "source": [
    "def createImageCubes(X, y, windowSize=8, removeZeroLabels = True):\n",
    "    margin = int((windowSize) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
    "    # split patches\n",
    "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
    "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
    "    patchIndex = 0\n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin , c - margin:c + margin ]   \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
    "            patchIndex = patchIndex + 1\n",
    "    if removeZeroLabels:\n",
    "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
    "        patchesLabels = patchesLabels[patchesLabels>0]\n",
    "        patchesLabels -= 1\n",
    "    return patchesData, patchesLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 5525,
     "status": "ok",
     "timestamp": 1602478409238,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "cnneGlFFNRVo",
    "outputId": "3b00138d-9d02-4b14-f6e2-2b1dc9ad8aeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((512, 217, 204), (512, 217))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = loadData(dataset)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 5518,
     "status": "ok",
     "timestamp": 1602478409239,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "TOGl1BmWNdyv"
   },
   "outputs": [],
   "source": [
    "K = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 30165,
     "status": "ok",
     "timestamp": 1602478433894,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "fTYzjiltNj8a",
    "outputId": "7bfa99db-15b8-40d1-83b2-b7d32d039c0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 217, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 3 if dataset == 'IP' else 3\n",
    "X,fa = applyFA(X,numComponents=K)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 31758,
     "status": "ok",
     "timestamp": 1602478435499,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "hiZiDsE0cN-O",
    "outputId": "acf836b7-666b-4104-c856-d4e0b1d1f84f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54129, 24, 24, 3), (54129,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = createImageCubes(X, y, windowSize=windowSize)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 31739,
     "status": "ok",
     "timestamp": 1602478435500,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "OMYMZxnDcSHb",
    "outputId": "8e9b4564-aff1-40e2-b081-7154c18d5d77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5412, 24, 24, 3), (48717, 24, 24, 3), (5412,), (48717,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = splitTrainTestSet(X, y, test_ratio)\n",
    "\n",
    "Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 31716,
     "status": "ok",
     "timestamp": 1602478435501,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "VBvWzipfcZDK",
    "outputId": "af402f16-e7ee-4272-c243-ae05646c8317"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5412, 24, 24, 3, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = Xtrain.reshape(-1, windowSize, windowSize, K, 1)\n",
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 31703,
     "status": "ok",
     "timestamp": 1602478435502,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "lxr7HMjocZvd",
    "outputId": "cb12450a-7ffc-44a2-d57b-2e42e0402ec4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5412, 16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain = np_utils.to_categorical(ytrain)\n",
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 31691,
     "status": "ok",
     "timestamp": 1602478435502,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "pAmd40PJcdog"
   },
   "outputs": [],
   "source": [
    "S1 = windowSize\n",
    "L1 = K\n",
    "output_units = 9 if (dataset == 'PU' or dataset == 'PC') else 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 31687,
     "status": "ok",
     "timestamp": 1602478435503,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "wQDctC5hdHlP"
   },
   "outputs": [],
   "source": [
    "def WaveletTransformAxisY(batch_img):\n",
    "    odd_img  = batch_img[:,0::2]\n",
    "    even_img = batch_img[:,1::2]\n",
    "    L = (odd_img + even_img) / 2.0\n",
    "    H = Kb.abs(odd_img - even_img)\n",
    "    return L, H\n",
    "\n",
    "def WaveletTransformAxisX(batch_img):\n",
    "    # transpose + fliplr\n",
    "    tmp_batch = Kb.permute_dimensions(batch_img, [0, 2, 1])[:,:,::-1]\n",
    "    _dst_L, _dst_H = WaveletTransformAxisY(tmp_batch)\n",
    "    # transpose + flipud\n",
    "    dst_L = Kb.permute_dimensions(_dst_L, [0, 2, 1])[:,::-1,...]\n",
    "    dst_H = Kb.permute_dimensions(_dst_H, [0, 2, 1])[:,::-1,...]\n",
    "    return dst_L, dst_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 31679,
     "status": "ok",
     "timestamp": 1602478435503,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "NCAUyHZFdPfN"
   },
   "outputs": [],
   "source": [
    "def Wavelet(batch_image):\n",
    "    # make channel first image\n",
    "    batch_image = Kb.permute_dimensions(batch_image, [0, 3, 1, 2])\n",
    "    r = batch_image[:,0]\n",
    "    g = batch_image[:,1]\n",
    "    b = batch_image[:,2]\n",
    "\n",
    "    # level 1 decomposition\n",
    "    wavelet_L, wavelet_H = WaveletTransformAxisY(r)\n",
    "    r_wavelet_LL, r_wavelet_LH = WaveletTransformAxisX(wavelet_L)\n",
    "    r_wavelet_HL, r_wavelet_HH = WaveletTransformAxisX(wavelet_H)\n",
    "\n",
    "    wavelet_L, wavelet_H = WaveletTransformAxisY(g)\n",
    "    g_wavelet_LL, g_wavelet_LH = WaveletTransformAxisX(wavelet_L)\n",
    "    g_wavelet_HL, g_wavelet_HH = WaveletTransformAxisX(wavelet_H)\n",
    "\n",
    "    wavelet_L, wavelet_H = WaveletTransformAxisY(b)\n",
    "    b_wavelet_LL, b_wavelet_LH = WaveletTransformAxisX(wavelet_L)\n",
    "    b_wavelet_HL, b_wavelet_HH = WaveletTransformAxisX(wavelet_H)\n",
    "\n",
    "    wavelet_data = [r_wavelet_LL, r_wavelet_LH, r_wavelet_HL, r_wavelet_HH, \n",
    "                    g_wavelet_LL, g_wavelet_LH, g_wavelet_HL, g_wavelet_HH,\n",
    "                    b_wavelet_LL, b_wavelet_LH, b_wavelet_HL, b_wavelet_HH]\n",
    "    transform_batch = Kb.stack(wavelet_data, axis=1)\n",
    "\n",
    "    # level 2 decomposition\n",
    "    wavelet_L2, wavelet_H2 = WaveletTransformAxisY(r_wavelet_LL)\n",
    "    r_wavelet_LL2, r_wavelet_LH2 = WaveletTransformAxisX(wavelet_L2)\n",
    "    r_wavelet_HL2, r_wavelet_HH2 = WaveletTransformAxisX(wavelet_H2)\n",
    "\n",
    "    wavelet_L2, wavelet_H2 = WaveletTransformAxisY(g_wavelet_LL)\n",
    "    g_wavelet_LL2, g_wavelet_LH2 = WaveletTransformAxisX(wavelet_L2)\n",
    "    g_wavelet_HL2, g_wavelet_HH2 = WaveletTransformAxisX(wavelet_H2)\n",
    "\n",
    "    wavelet_L2, wavelet_H2 = WaveletTransformAxisY(b_wavelet_LL)\n",
    "    b_wavelet_LL2, b_wavelet_LH2 = WaveletTransformAxisX(wavelet_L2)\n",
    "    b_wavelet_HL2, b_wavelet_HH2 = WaveletTransformAxisX(wavelet_H2)\n",
    "\n",
    "\n",
    "    wavelet_data_l2 = [r_wavelet_LL2, r_wavelet_LH2, r_wavelet_HL2, r_wavelet_HH2, \n",
    "                    g_wavelet_LL2, g_wavelet_LH2, g_wavelet_HL2, g_wavelet_HH2,\n",
    "                    b_wavelet_LL2, b_wavelet_LH2, b_wavelet_HL2, b_wavelet_HH2]\n",
    "    transform_batch_l2 = Kb.stack(wavelet_data_l2, axis=1)\n",
    "\n",
    "    # level 3 decomposition\n",
    "    wavelet_L3, wavelet_H3 = WaveletTransformAxisY(r_wavelet_LL2)\n",
    "    r_wavelet_LL3, r_wavelet_LH3 = WaveletTransformAxisX(wavelet_L3)\n",
    "    r_wavelet_HL3, r_wavelet_HH3 = WaveletTransformAxisX(wavelet_H3)\n",
    "\n",
    "    wavelet_L3, wavelet_H3 = WaveletTransformAxisY(g_wavelet_LL2)\n",
    "    g_wavelet_LL3, g_wavelet_LH3 = WaveletTransformAxisX(wavelet_L3)\n",
    "    g_wavelet_HL3, g_wavelet_HH3 = WaveletTransformAxisX(wavelet_H3)\n",
    "\n",
    "    wavelet_L3, wavelet_H3 = WaveletTransformAxisY(b_wavelet_LL2)\n",
    "    b_wavelet_LL3, b_wavelet_LH3 = WaveletTransformAxisX(wavelet_L3)\n",
    "    b_wavelet_HL3, b_wavelet_HH3 = WaveletTransformAxisX(wavelet_H3)\n",
    "\n",
    "    wavelet_data_l3 = [r_wavelet_LL3, r_wavelet_LH3, r_wavelet_HL3, r_wavelet_HH3, \n",
    "                    g_wavelet_LL3, g_wavelet_LH3, g_wavelet_HL3, g_wavelet_HH3,\n",
    "                    b_wavelet_LL3, b_wavelet_LH3, b_wavelet_HL3, b_wavelet_HH3]\n",
    "    transform_batch_l3 = Kb.stack(wavelet_data_l3, axis=1)\n",
    "\n",
    "    # level 4 decomposition\n",
    "    wavelet_L4, wavelet_H4 = WaveletTransformAxisY(r_wavelet_LL3)\n",
    "    r_wavelet_LL4, r_wavelet_LH4 = WaveletTransformAxisX(wavelet_L4)\n",
    "    r_wavelet_HL4, r_wavelet_HH4 = WaveletTransformAxisX(wavelet_H4)\n",
    "\n",
    "    wavelet_L4, wavelet_H4 = WaveletTransformAxisY(g_wavelet_LL3)\n",
    "    g_wavelet_LL4, g_wavelet_LH4 = WaveletTransformAxisX(wavelet_L4)\n",
    "    g_wavelet_HL4, g_wavelet_HH4 = WaveletTransformAxisX(wavelet_H4)\n",
    "\n",
    "    wavelet_L3, wavelet_H3 = WaveletTransformAxisY(b_wavelet_LL3)\n",
    "    b_wavelet_LL4, b_wavelet_LH4 = WaveletTransformAxisX(wavelet_L4)\n",
    "    b_wavelet_HL4, b_wavelet_HH4 = WaveletTransformAxisX(wavelet_H4)\n",
    "\n",
    "\n",
    "    wavelet_data_l4 = [r_wavelet_LL4, r_wavelet_LH4, r_wavelet_HL4, r_wavelet_HH4, \n",
    "                    g_wavelet_LL4, g_wavelet_LH4, g_wavelet_HL4, g_wavelet_HH4,\n",
    "                    b_wavelet_LL4, b_wavelet_LH4, b_wavelet_HL4, b_wavelet_HH4]\n",
    "    transform_batch_l4 = Kb.stack(wavelet_data_l4, axis=1)\n",
    "\n",
    "    # print('shape before')\n",
    "    # print(transform_batch.shape)\n",
    "    # print(transform_batch_l2.shape)\n",
    "    # print(transform_batch_l3.shape)\n",
    "    # print(transform_batch_l4.shape)\n",
    "\n",
    "    decom_level_1 = Kb.permute_dimensions(transform_batch, [0, 2, 3, 1])\n",
    "    decom_level_2 = Kb.permute_dimensions(transform_batch_l2, [0, 2, 3, 1])\n",
    "    decom_level_3 = Kb.permute_dimensions(transform_batch_l3, [0, 2, 3, 1])\n",
    "    decom_level_4 = Kb.permute_dimensions(transform_batch_l4, [0, 2, 3, 1])\n",
    "    \n",
    "    # print('shape after')\n",
    "    # print(decom_level_1.shape)\n",
    "    # print(decom_level_2.shape)\n",
    "    # print(decom_level_3.shape)\n",
    "    # print(decom_level_4.shape)\n",
    "    return [decom_level_1, decom_level_2, decom_level_3, decom_level_4]\n",
    "\n",
    "\n",
    "def Wavelet_out_shape(input_shapes):\n",
    "    # print('in to shape')\n",
    "    return [tuple([None, 112, 112, 12]), tuple([None, 56, 56, 12]), \n",
    "            tuple([None, 28, 28, 12]), tuple([None, 14, 14, 12])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 31664,
     "status": "ok",
     "timestamp": 1602478435504,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "GVN-IuF7e2OB",
    "outputId": "2d2cbade-23cf-4833-8750-3755e381c91f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(8, 12, 12, 12), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8, 6, 6, 12), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8, 3, 3, 12), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(8, 2, 2, 12), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_batch = Kb.zeros(shape=(8, 24, 24, 3), dtype='float32')\n",
    "Wavelet(img_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 31657,
     "status": "ok",
     "timestamp": 1602478435506,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "5taLY_ljgFq3"
   },
   "outputs": [],
   "source": [
    "def get_wavelet_cnn_model():\n",
    " \n",
    "    input_shape =  24, 24, 3\n",
    " \n",
    "    input_ = Input(input_shape, name='the_input')\n",
    "    # wavelet = Lambda(Wavelet, name='wavelet')\n",
    "    wavelet = Lambda(Wavelet, Wavelet_out_shape, name='wavelet')\n",
    "    input_l1, input_l2, input_l3, input_l4 = wavelet(input_)\n",
    "    # print(input_l1)\n",
    "    # print(input_l2)\n",
    "    # print(input_l3)\n",
    "    # print(input_l4)\n",
    "    # level one decomposition starts\n",
    "    conv_1 = Conv2D(64, kernel_size=(3, 3), padding='same', name='conv_1')(input_l1)\n",
    "    norm_1 = BatchNormalization(name='norm_1')(conv_1)\n",
    "    relu_1 = Activation('relu', name='relu_1')(norm_1)\n",
    " \n",
    "    conv_1_2 = Conv2D(64, kernel_size=(3, 3), strides=(2, 2), padding='same', name='conv_1_2')(relu_1)\n",
    "    norm_1_2 = BatchNormalization(name='norm_1_2')(conv_1_2)\n",
    "    relu_1_2 = Activation('relu', name='relu_1_2')(norm_1_2)\n",
    " \n",
    "    # level two decomposition starts\n",
    "    conv_a = Conv2D(filters=64, kernel_size=(3, 3), padding='same', name='conv_a')(input_l2)\n",
    "    norm_a = BatchNormalization(name='norm_a')(conv_a)\n",
    "    relu_a = Activation('relu', name='relu_a')(norm_a)\n",
    " \n",
    "    # concate level one and level two decomposition\n",
    "    concate_level_2 = concatenate([relu_1_2, relu_a])\n",
    "    conv_2 = Conv2D(128, kernel_size=(3, 3), padding='same', name='conv_2')(concate_level_2)\n",
    "    norm_2 = BatchNormalization(name='norm_2')(conv_2)\n",
    "    relu_2 = Activation('relu', name='relu_2')(norm_2)\n",
    " \n",
    "    conv_2_2 = Conv2D(128, kernel_size=(3, 3), strides=(2, 2), padding='same', name='conv_2_2')(relu_2)\n",
    "    norm_2_2 = BatchNormalization(name='norm_2_2')(conv_2_2)\n",
    "    relu_2_2 = Activation('relu', name='relu_2_2')(norm_2_2)\n",
    " \n",
    "    # level three decomposition starts \n",
    "    conv_b = Conv2D(filters=64, kernel_size=(3, 3), padding='same', name='conv_b')(input_l3)\n",
    "    norm_b = BatchNormalization(name='norm_b')(conv_b)\n",
    "    relu_b = Activation('relu', name='relu_b')(norm_b)\n",
    " \n",
    "    conv_b_2 = Conv2D(128, kernel_size=(3, 3), padding='same', name='conv_b_2')(relu_b)\n",
    "    norm_b_2 = BatchNormalization(name='norm_b_2')(conv_b_2)\n",
    "    relu_b_2 = Activation('relu', name='relu_b_2')(norm_b_2)\n",
    " \n",
    "    # concate level two and level three decomposition \n",
    "    concate_level_3 = concatenate([relu_2_2, relu_b_2])\n",
    "    conv_3 = Conv2D(256, kernel_size=(3, 3), padding='same', name='conv_3')(concate_level_3)\n",
    "    norm_3 = BatchNormalization(name='nomr_3')(conv_3)\n",
    "    relu_3 = Activation('relu', name='relu_3')(norm_3)\n",
    " \n",
    "    conv_3_2 = Conv2D(256, kernel_size=(3, 3), strides=(2, 2), padding='same', name='conv_3_2')(relu_3)\n",
    "    norm_3_2 = BatchNormalization(name='norm_3_2')(conv_3_2)\n",
    "    relu_3_2 = Activation('relu', name='relu_3_2')(norm_3_2)\n",
    " \n",
    "    # level four decomposition start\n",
    "    conv_c = Conv2D(64, kernel_size=(3, 3), padding='same', name='conv_c')(input_l4)\n",
    "    norm_c = BatchNormalization(name='norm_c')(conv_c)\n",
    "    relu_c = Activation('relu', name='relu_c')(norm_c)\n",
    " \n",
    "    conv_c_2 = Conv2D(256, kernel_size=(3, 3), padding='same', name='conv_c_2')(relu_c)\n",
    "    norm_c_2 = BatchNormalization(name='norm_c_2')(conv_c_2)\n",
    "    relu_c_2 = Activation('relu', name='relu_c_2')(norm_c_2)\n",
    " \n",
    "    conv_c_3 = Conv2D(256, kernel_size=(3, 3), padding='same', name='conv_c_3')(relu_c_2)\n",
    "    norm_c_3 = BatchNormalization(name='norm_c_3')(conv_c_3)\n",
    "    relu_c_3 = Activation('relu', name='relu_c_3')(norm_c_3)\n",
    " \n",
    "    # concate level level three and level four decomposition\n",
    "    concate_level_4 = concatenate([relu_3_2, relu_c_3])\n",
    "    conv_4 = Conv2D(256, kernel_size=(3, 3), padding='same', name='conv_4')(concate_level_4)\n",
    "    norm_4 = BatchNormalization(name='norm_4')(conv_4)\n",
    "    relu_4 = Activation('relu', name='relu_4')(norm_4)\n",
    " \n",
    "    conv_4_2 = Conv2D(256, kernel_size=(3, 3), strides=(2, 2), padding='same', name='conv_4_2')(relu_4)\n",
    "    norm_4_2 = BatchNormalization(name='norm_4_2')(conv_4_2)\n",
    "    relu_4_2 = Activation('relu', name='relu_4_2')(norm_4_2)\n",
    " \n",
    "    conv_5_1 = Conv2D(128, kernel_size=(3, 3), padding='same', name='conv_5_1')(relu_4_2)\n",
    "    norm_5_1 = BatchNormalization(name='norm_5_1')(conv_5_1)\n",
    "    relu_5_1 = Activation('relu', name='relu_5_1')(norm_5_1)\n",
    " \n",
    "    pool_5_1 = AveragePooling2D(pool_size=(7, 7), strides=1, padding='same', name='avg_pool_5_1')(relu_5_1)\n",
    "    #flat_5_1 = Flatten(name='flat_5_1')(pool_5_1) \n",
    " \n",
    "    #fc_5 = Dense(2048, name='fc_5')(flat_5_1)\n",
    "    #norm_5 = BatchNormalization(name='norm_5')(fc_5)\n",
    "    #relu_5 = Activation('relu', name='relu_5')(norm_5)\n",
    "    #drop_5 = Dropout(0.5, name='drop_5')(relu_5)\n",
    " \n",
    "    #fc_6 = Dense(2048, name='fc_6')(drop_5)\n",
    "    #norm_6 = BatchNormalization(name='norm_6')(fc_6)\n",
    "    #relu_6 = Activation('relu', name='relu_6')(norm_6)\n",
    "    #drop_6 = Dropout(0.5, name='drop_6')(relu_6)\n",
    "    flatten_layer = Flatten()(pool_5_1)\n",
    " \n",
    "    dense_layer1 = Dense(units=2048, activation='relu')(flatten_layer)\n",
    "    dense_layer1 = Dropout(0.4)(dense_layer1)\n",
    "    dense_layer2 = Dense(units=1024, activation='relu')(dense_layer1)\n",
    "    dense_layer2 = Dropout(0.4)(dense_layer2)\n",
    "    output_layer = Dense(units=output_units, activation='softmax')(dense_layer2)\n",
    " \n",
    "    model = Model(inputs=input_, outputs=output_layer)\n",
    "    model.summary()\n",
    "    plot_model(model, to_file='wavelet_cnn_0.5.png')\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 32872,
     "status": "ok",
     "timestamp": 1602478436734,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "iVgd4QmzgKKq",
    "outputId": "32d4779c-5699-49b0-eaef-613ac3ef7968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          [(None, 24, 24, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "wavelet (Lambda)                [(None, 12, 12, 12), 0           the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 12, 12, 64)   6976        wavelet[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_1 (BatchNormalization)     (None, 12, 12, 64)   256         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_1 (Activation)             (None, 12, 12, 64)   0           norm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_2 (Conv2D)               (None, 6, 6, 64)     36928       relu_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_a (Conv2D)                 (None, 6, 6, 64)     6976        wavelet[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_1_2 (BatchNormalization)   (None, 6, 6, 64)     256         conv_1_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_a (BatchNormalization)     (None, 6, 6, 64)     256         conv_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_1_2 (Activation)           (None, 6, 6, 64)     0           norm_1_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_a (Activation)             (None, 6, 6, 64)     0           norm_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 6, 128)    0           relu_1_2[0][0]                   \n",
      "                                                                 relu_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 6, 6, 128)    147584      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_b (Conv2D)                 (None, 3, 3, 64)     6976        wavelet[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_2 (BatchNormalization)     (None, 6, 6, 128)    512         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "norm_b (BatchNormalization)     (None, 3, 3, 64)     256         conv_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_2 (Activation)             (None, 6, 6, 128)    0           norm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_b (Activation)             (None, 3, 3, 64)     0           norm_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_2 (Conv2D)               (None, 3, 3, 128)    147584      relu_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_b_2 (Conv2D)               (None, 3, 3, 128)    73856       relu_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "norm_2_2 (BatchNormalization)   (None, 3, 3, 128)    512         conv_2_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_b_2 (BatchNormalization)   (None, 3, 3, 128)    512         conv_b_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_c (Conv2D)                 (None, 2, 2, 64)     6976        wavelet[0][3]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_2_2 (Activation)           (None, 3, 3, 128)    0           norm_2_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_b_2 (Activation)           (None, 3, 3, 128)    0           norm_b_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_c (BatchNormalization)     (None, 2, 2, 64)     256         conv_c[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 3, 256)    0           relu_2_2[0][0]                   \n",
      "                                                                 relu_b_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_c (Activation)             (None, 2, 2, 64)     0           norm_c[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 3, 3, 256)    590080      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_c_2 (Conv2D)               (None, 2, 2, 256)    147712      relu_c[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "nomr_3 (BatchNormalization)     (None, 3, 3, 256)    1024        conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "norm_c_2 (BatchNormalization)   (None, 2, 2, 256)    1024        conv_c_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_3 (Activation)             (None, 3, 3, 256)    0           nomr_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_c_2 (Activation)           (None, 2, 2, 256)    0           norm_c_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_2 (Conv2D)               (None, 2, 2, 256)    590080      relu_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_c_3 (Conv2D)               (None, 2, 2, 256)    590080      relu_c_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_3_2 (BatchNormalization)   (None, 2, 2, 256)    1024        conv_3_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_c_3 (BatchNormalization)   (None, 2, 2, 256)    1024        conv_c_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_3_2 (Activation)           (None, 2, 2, 256)    0           norm_3_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_c_3 (Activation)           (None, 2, 2, 256)    0           norm_c_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2, 2, 512)    0           relu_3_2[0][0]                   \n",
      "                                                                 relu_c_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 2, 2, 256)    1179904     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_4 (BatchNormalization)     (None, 2, 2, 256)    1024        conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_4 (Activation)             (None, 2, 2, 256)    0           norm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4_2 (Conv2D)               (None, 1, 1, 256)    590080      relu_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "norm_4_2 (BatchNormalization)   (None, 1, 1, 256)    1024        conv_4_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_4_2 (Activation)           (None, 1, 1, 256)    0           norm_4_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_5_1 (Conv2D)               (None, 1, 1, 128)    295040      relu_4_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_5_1 (BatchNormalization)   (None, 1, 1, 128)    512         conv_5_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_5_1 (Activation)           (None, 1, 1, 128)    0           norm_5_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool_5_1 (AveragePooling2D) (None, 1, 1, 128)    0           relu_5_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 128)          0           avg_pool_5_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048)         264192      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2048)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           16400       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,805,072\n",
      "Trainable params: 6,800,336\n",
      "Non-trainable params: 4,736\n",
      "__________________________________________________________________________________________________\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "model = get_wavelet_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 32861,
     "status": "ok",
     "timestamp": 1602478436735,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "OYsuViCjhSA3"
   },
   "outputs": [],
   "source": [
    "#adam = Adam(lr=0.001, decay=1e-06)\n",
    "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 32854,
     "status": "ok",
     "timestamp": 1602478436736,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "sUQZa9UD-rsL"
   },
   "outputs": [],
   "source": [
    "filepath = \"best-model.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=False, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 417831,
     "status": "ok",
     "timestamp": 1602478821720,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "OVwsWGf1hfg3",
    "outputId": "66ced090-c536-4f79-9bee-71ded4683b4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6525 - accuracy: 0.7882\n",
      "Epoch 00001: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 19s 104ms/step - loss: 0.6525 - accuracy: 0.7882\n",
      "Epoch 2/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.1720 - accuracy: 0.9448\n",
      "Epoch 00002: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 19s 105ms/step - loss: 0.1720 - accuracy: 0.9448\n",
      "Epoch 3/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.1618 - accuracy: 0.9429\n",
      "Epoch 00003: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.1618 - accuracy: 0.9429\n",
      "Epoch 4/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0926 - accuracy: 0.9695\n",
      "Epoch 00004: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0926 - accuracy: 0.9695\n",
      "Epoch 5/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 0.9808\n",
      "Epoch 00005: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0671 - accuracy: 0.9808\n",
      "Epoch 6/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9763\n",
      "Epoch 00006: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0748 - accuracy: 0.9763\n",
      "Epoch 7/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.9834\n",
      "Epoch 00007: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0502 - accuracy: 0.9834\n",
      "Epoch 8/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 0.9911\n",
      "Epoch 00008: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0267 - accuracy: 0.9911\n",
      "Epoch 9/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9893\n",
      "Epoch 00009: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0343 - accuracy: 0.9893\n",
      "Epoch 10/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9921\n",
      "Epoch 00010: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0257 - accuracy: 0.9921\n",
      "Epoch 11/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9861\n",
      "Epoch 00011: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0510 - accuracy: 0.9861\n",
      "Epoch 12/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.9898\n",
      "Epoch 00012: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0394 - accuracy: 0.9898\n",
      "Epoch 13/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9933\n",
      "Epoch 00013: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0195 - accuracy: 0.9933\n",
      "Epoch 14/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 0.9884\n",
      "Epoch 00014: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0405 - accuracy: 0.9884\n",
      "Epoch 15/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9969\n",
      "Epoch 00015: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 20s 110ms/step - loss: 0.0145 - accuracy: 0.9969\n",
      "Epoch 16/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9913\n",
      "Epoch 00016: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 22s 119ms/step - loss: 0.0238 - accuracy: 0.9913\n",
      "Epoch 17/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9884\n",
      "Epoch 00017: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 101ms/step - loss: 0.0423 - accuracy: 0.9884\n",
      "Epoch 18/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9948\n",
      "Epoch 00018: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 20s 110ms/step - loss: 0.0203 - accuracy: 0.9948\n",
      "Epoch 19/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0278 - accuracy: 0.9917\n",
      "Epoch 00019: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 19s 104ms/step - loss: 0.0278 - accuracy: 0.9917\n",
      "Epoch 20/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9972\n",
      "Epoch 00020: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 21s 114ms/step - loss: 0.0102 - accuracy: 0.9972\n",
      "Epoch 21/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9871 E\n",
      "Epoch 00021: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0539 - accuracy: 0.9871\n",
      "Epoch 22/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9969\n",
      "Epoch 00022: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 19s 105ms/step - loss: 0.0105 - accuracy: 0.9969\n",
      "Epoch 23/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9967\n",
      "Epoch 00023: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 19s 104ms/step - loss: 0.0112 - accuracy: 0.9967\n",
      "Epoch 24/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9939\n",
      "Epoch 00024: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 19s 104ms/step - loss: 0.0189 - accuracy: 0.9939\n",
      "Epoch 25/150\n",
      "180/181 [============================>.] - ETA: 0s - loss: 0.0294 - accuracy: 0.9919\n",
      "Epoch 00025: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 20s 111ms/step - loss: 0.0294 - accuracy: 0.9919\n",
      "Epoch 26/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9956\n",
      "Epoch 00026: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 21s 115ms/step - loss: 0.0182 - accuracy: 0.9956\n",
      "Epoch 27/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9972\n",
      "Epoch 00027: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 19s 107ms/step - loss: 0.0084 - accuracy: 0.9972\n",
      "Epoch 28/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9983\n",
      "Epoch 00028: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 102ms/step - loss: 0.0052 - accuracy: 0.9983\n",
      "Epoch 29/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9965\n",
      "Epoch 00029: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 20s 113ms/step - loss: 0.0102 - accuracy: 0.9965\n",
      "Epoch 30/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9958\n",
      "Epoch 00030: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 21s 114ms/step - loss: 0.0122 - accuracy: 0.9958\n",
      "Epoch 31/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9950\n",
      "Epoch 00031: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 19s 104ms/step - loss: 0.0184 - accuracy: 0.9950\n",
      "Epoch 32/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9987\n",
      "Epoch 00032: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0054 - accuracy: 0.9987\n",
      "Epoch 33/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 0.9921\n",
      "Epoch 00033: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 19s 103ms/step - loss: 0.0282 - accuracy: 0.9921\n",
      "Epoch 34/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9972\n",
      "Epoch 00034: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 21s 114ms/step - loss: 0.0078 - accuracy: 0.9972\n",
      "Epoch 35/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9965\n",
      "Epoch 00035: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 19s 107ms/step - loss: 0.0120 - accuracy: 0.9965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9974\n",
      "Epoch 00036: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 19s 102ms/step - loss: 0.0082 - accuracy: 0.9974\n",
      "Epoch 37/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9982\n",
      "Epoch 00037: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0060 - accuracy: 0.9982\n",
      "Epoch 38/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9976\n",
      "Epoch 00038: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0064 - accuracy: 0.9976\n",
      "Epoch 39/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9978\n",
      "Epoch 00039: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 0.0062 - accuracy: 0.9978\n",
      "Epoch 40/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9985\n",
      "Epoch 00040: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 102ms/step - loss: 0.0070 - accuracy: 0.9985\n",
      "Epoch 41/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9983\n",
      "Epoch 00041: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 101ms/step - loss: 0.0054 - accuracy: 0.9983\n",
      "Epoch 42/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 00042: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 19s 106ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 43/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9978\n",
      "Epoch 00043: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 0.0073 - accuracy: 0.9978\n",
      "Epoch 44/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9959\n",
      "Epoch 00044: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 19s 102ms/step - loss: 0.0174 - accuracy: 0.9959\n",
      "Epoch 45/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9974\n",
      "Epoch 00045: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 102ms/step - loss: 0.0099 - accuracy: 0.9974\n",
      "Epoch 46/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 00046: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 47/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9976\n",
      "Epoch 00047: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0087 - accuracy: 0.9976\n",
      "Epoch 48/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 00048: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 49/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 7.0718e-04 - accuracy: 0.9996\n",
      "Epoch 00049: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 7.0718e-04 - accuracy: 0.9996\n",
      "Epoch 50/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 3.8591e-04 - accuracy: 1.0000\n",
      "Epoch 00050: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 3.8591e-04 - accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9994\n",
      "Epoch 00051: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0013 - accuracy: 0.9994\n",
      "Epoch 52/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9941\n",
      "Epoch 00052: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0269 - accuracy: 0.9941\n",
      "Epoch 53/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9993\n",
      "Epoch 00053: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0043 - accuracy: 0.9993\n",
      "Epoch 54/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 00054: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 55/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 00055: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 56/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 00056: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 57/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 00057: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 58/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9978\n",
      "Epoch 00058: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0078 - accuracy: 0.9978\n",
      "Epoch 59/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9969\n",
      "Epoch 00059: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0087 - accuracy: 0.9969\n",
      "Epoch 60/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9991\n",
      "Epoch 00060: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0033 - accuracy: 0.9991\n",
      "Epoch 61/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9985\n",
      "Epoch 00061: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0052 - accuracy: 0.9985\n",
      "Epoch 62/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 6.0274e-04 - accuracy: 1.0000\n",
      "Epoch 00062: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 6.0274e-04 - accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 8.9559e-04 - accuracy: 0.9996\n",
      "Epoch 00063: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 8.9559e-04 - accuracy: 0.9996\n",
      "Epoch 64/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9983 ETA: \n",
      "Epoch 00064: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0062 - accuracy: 0.9983\n",
      "Epoch 65/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9970\n",
      "Epoch 00065: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0107 - accuracy: 0.9970\n",
      "Epoch 66/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9985\n",
      "Epoch 00066: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0040 - accuracy: 0.9985\n",
      "Epoch 67/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9993\n",
      "Epoch 00067: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0054 - accuracy: 0.9993\n",
      "Epoch 68/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9989\n",
      "Epoch 00068: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0029 - accuracy: 0.9989\n",
      "Epoch 69/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9989\n",
      "Epoch 00069: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0031 - accuracy: 0.9989\n",
      "Epoch 70/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9991\n",
      "Epoch 00070: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0032 - accuracy: 0.9991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9980\n",
      "Epoch 00071: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0059 - accuracy: 0.9980\n",
      "Epoch 72/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9987\n",
      "Epoch 00072: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0062 - accuracy: 0.9987\n",
      "Epoch 73/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9991\n",
      "Epoch 00073: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0038 - accuracy: 0.9991\n",
      "Epoch 74/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n",
      "Epoch 00074: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0027 - accuracy: 0.9991\n",
      "Epoch 75/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9991\n",
      "Epoch 00075: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 20s 108ms/step - loss: 0.0048 - accuracy: 0.9991\n",
      "Epoch 76/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 4.0937e-04 - accuracy: 1.0000\n",
      "Epoch 00076: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 101ms/step - loss: 4.0937e-04 - accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9991\n",
      "Epoch 00077: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0021 - accuracy: 0.9991\n",
      "Epoch 78/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9982\n",
      "Epoch 00078: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0063 - accuracy: 0.9982\n",
      "Epoch 79/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9996\n",
      "Epoch 00079: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0025 - accuracy: 0.9996\n",
      "Epoch 80/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9939\n",
      "Epoch 00080: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0190 - accuracy: 0.9939\n",
      "Epoch 81/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9974\n",
      "Epoch 00081: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0071 - accuracy: 0.9974\n",
      "Epoch 82/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9961\n",
      "Epoch 00082: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0131 - accuracy: 0.9961\n",
      "Epoch 83/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9985\n",
      "Epoch 00083: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0052 - accuracy: 0.9985\n",
      "Epoch 84/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9994\n",
      "Epoch 00084: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0015 - accuracy: 0.9994\n",
      "Epoch 85/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9987\n",
      "Epoch 00085: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0045 - accuracy: 0.9987\n",
      "Epoch 86/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9985\n",
      "Epoch 00086: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0068 - accuracy: 0.9985\n",
      "Epoch 87/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 00087: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 88/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9969\n",
      "Epoch 00088: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0102 - accuracy: 0.9969\n",
      "Epoch 89/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9970\n",
      "Epoch 00089: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0089 - accuracy: 0.9970\n",
      "Epoch 90/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9978\n",
      "Epoch 00090: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0073 - accuracy: 0.9978\n",
      "Epoch 91/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 7.5099e-04 - accuracy: 0.9998\n",
      "Epoch 00091: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 20s 108ms/step - loss: 7.5099e-04 - accuracy: 0.9998\n",
      "Epoch 92/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9994    \n",
      "Epoch 00092: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 19s 107ms/step - loss: 0.0012 - accuracy: 0.9994\n",
      "Epoch 93/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 00093: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 101ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 94/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 5.6871e-04 - accuracy: 1.0000\n",
      "Epoch 00094: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 5.6871e-04 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.7800e-04 - accuracy: 1.0000\n",
      "Epoch 00095: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 1.7800e-04 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 2.1147e-04 - accuracy: 1.0000\n",
      "Epoch 00096: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 2.1147e-04 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 2.4996e-04 - accuracy: 1.0000\n",
      "Epoch 00097: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 2.4996e-04 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9991\n",
      "Epoch 00098: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 0.0043 - accuracy: 0.9991\n",
      "Epoch 99/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 00099: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 100/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 7.3477e-04 - accuracy: 0.9998\n",
      "Epoch 00100: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 7.3477e-04 - accuracy: 0.9998\n",
      "Epoch 101/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9991\n",
      "Epoch 00101: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0043 - accuracy: 0.9991\n",
      "Epoch 102/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 2.7936e-04 - accuracy: 1.0000\n",
      "Epoch 00102: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 2.7936e-04 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 3.2449e-04 - accuracy: 1.0000\n",
      "Epoch 00103: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 3.2449e-04 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.6277e-04 - accuracy: 1.0000\n",
      "Epoch 00104: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 1.6277e-04 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9996\n",
      "Epoch 00105: saving model to best-model.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - 19s 102ms/step - loss: 0.0024 - accuracy: 0.9996\n",
      "Epoch 106/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 9.4074e-04 - accuracy: 0.9998\n",
      "Epoch 00106: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 9.4074e-04 - accuracy: 0.9998\n",
      "Epoch 107/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 6.9615e-04 - accuracy: 0.9996\n",
      "Epoch 00107: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 6.9615e-04 - accuracy: 0.9996\n",
      "Epoch 108/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 00108: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 109/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9987\n",
      "Epoch 00109: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0066 - accuracy: 0.9987\n",
      "Epoch 110/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9998\n",
      "Epoch 00110: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0015 - accuracy: 0.9998\n",
      "Epoch 111/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 5.1282e-04 - accuracy: 0.9998\n",
      "Epoch 00111: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 5.1282e-04 - accuracy: 0.9998\n",
      "Epoch 112/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9993\n",
      "Epoch 00112: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0038 - accuracy: 0.9993\n",
      "Epoch 113/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 4.8119e-04 - accuracy: 1.0000\n",
      "Epoch 00113: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 4.8119e-04 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 2.0273e-04 - accuracy: 1.0000\n",
      "Epoch 00114: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 2.0273e-04 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 2.2046e-04 - accuracy: 1.0000\n",
      "Epoch 00115: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 2.2046e-04 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 9.9546e-05 - accuracy: 1.0000\n",
      "Epoch 00116: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 9.9546e-05 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9980\n",
      "Epoch 00117: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0054 - accuracy: 0.9980\n",
      "Epoch 118/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 9.0097e-04 - accuracy: 0.9996\n",
      "Epoch 00118: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 9.0097e-04 - accuracy: 0.9996\n",
      "Epoch 119/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9994\n",
      "Epoch 00119: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0067 - accuracy: 0.9994\n",
      "Epoch 120/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 00120: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 121/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9993\n",
      "Epoch 00121: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 0.0011 - accuracy: 0.9993\n",
      "Epoch 122/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 7.7555e-04 - accuracy: 0.9998\n",
      "Epoch 00122: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 7.7555e-04 - accuracy: 0.9998\n",
      "Epoch 123/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9991\n",
      "Epoch 00123: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0022 - accuracy: 0.9991\n",
      "Epoch 124/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9989\n",
      "Epoch 00124: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 0.0042 - accuracy: 0.9989\n",
      "Epoch 125/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 00125: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 126/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9998\n",
      "Epoch 00126: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 101ms/step - loss: 0.0018 - accuracy: 0.9998\n",
      "Epoch 127/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 00127: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 19s 102ms/step - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 128/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 4.7869e-04 - accuracy: 1.0000\n",
      "Epoch 00128: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 19s 105ms/step - loss: 4.7869e-04 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 3.3301e-04 - accuracy: 1.0000\n",
      "Epoch 00129: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 3.3301e-04 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.0445e-04 - accuracy: 1.0000\n",
      "Epoch 00130: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 1.0445e-04 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.8951e-04 - accuracy: 1.0000\n",
      "Epoch 00131: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 1.8951e-04 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.3279e-04 - accuracy: 1.0000\n",
      "Epoch 00132: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 1.3279e-04 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 8.5358e-05 - accuracy: 1.0000 ETA: 1s - loss:\n",
      "Epoch 00133: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 8.5358e-05 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9994\n",
      "Epoch 00134: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 0.0036 - accuracy: 0.9994\n",
      "Epoch 135/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9998\n",
      "Epoch 00135: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 0.0019 - accuracy: 0.9998\n",
      "Epoch 136/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 2.0812e-04 - accuracy: 1.0000\n",
      "Epoch 00136: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 2.0812e-04 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 2.4933e-04 - accuracy: 1.0000\n",
      "Epoch 00137: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 101ms/step - loss: 2.4933e-04 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989\n",
      "Epoch 00138: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 0.0036 - accuracy: 0.9989\n",
      "Epoch 139/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 3.0098e-04 - accuracy: 1.0000\n",
      "Epoch 00139: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 3.0098e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 00140: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 20s 110ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 141/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9972\n",
      "Epoch 00141: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 19s 106ms/step - loss: 0.0101 - accuracy: 0.9972\n",
      "Epoch 142/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9998\n",
      "Epoch 00142: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 0.0018 - accuracy: 0.9998\n",
      "Epoch 143/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 6.1224e-04 - accuracy: 0.9998\n",
      "Epoch 00143: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 99ms/step - loss: 6.1224e-04 - accuracy: 0.9998\n",
      "Epoch 144/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 00144: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 145/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 00145: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 100ms/step - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 146/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9996    \n",
      "Epoch 00146: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 147/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 00147: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 148/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.0186e-04 - accuracy: 1.0000\n",
      "Epoch 00148: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 98ms/step - loss: 1.0186e-04 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9993\n",
      "Epoch 00149: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 18s 102ms/step - loss: 0.0036 - accuracy: 0.9993\n",
      "Epoch 150/150\n",
      "181/181 [==============================] - ETA: 0s - loss: 4.9897e-04 - accuracy: 1.0000\n",
      "Epoch 00150: saving model to best-model.hdf5\n",
      "181/181 [==============================] - 19s 107ms/step - loss: 4.9897e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=Xtrain, y=ytrain, batch_size = 30, epochs=150, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5-BLNivkkD2"
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "executionInfo": {
     "elapsed": 417824,
     "status": "ok",
     "timestamp": 1602478821723,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "rzi0kGwckZIh",
    "outputId": "860ced41-4c23-4c7b-d0d9-88b35f1d005f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24a067785b0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAasAAAGbCAYAAAB6a7/AAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA0kUlEQVR4nO3deXyV5Zn/8c91TvaEJCCQQBI2RZBFUSLuGmxVtIvVWovTdrrYsdpa2xntYjvTdmZ+HTvdnZm2DLW2tqNStS7YutOmWhdEVtkCYU2AsJOVLCfn/v1xTmIIgQSSePLc+b5fL17kPOfJc66cLN9z38917secc4iIiAxkoUQXICIi0h2FlYiIDHgKKxERGfAUViIiMuAprEREZMBLStQDDx8+3I0bN67Xx6mvryczM7P3BSVIkOsPcu2g+hMpyLWD6u9PS5cu3eecG9F5e8LCaty4cbz11lu9Pk5paSklJSW9LyhBglx/kGsH1Z9IQa4dVH9/MrNtXW3XNKCIiAx4CisRERnwFFYiIjLgKaxERGTAU1iJiMiAp7ASEZEBT2ElIiIDnsJKREQGPIWViIgMeAorEREZ8BRWIiIy4CmsRERkwFNYiYjIgKewEhGRAS/QYbV1Xz17G6KJLkNERPpZoMPqiw8v5//WNSe6DBER6WeBDquQQdQlugoREelvwQ6rkOEUViIi3gt2WJkRRWklIuK7gIcVGlmJiAwCAQ8r0zkrEZFBIPBhpawSEfFfoMMqHNLISkRkMAh0WJnOWYmIDAqBDqtYN6CIiPgu0GEV1vusREQGhUCHlVawEBEZHAIeVuoGFBEZDIIfVpoHFBHxXrDDKqRpQBGRwSDYYaVuQBGRQSHwYaVZQBER/wU6rLSChYjI4BDosDJD3YAiIoNAoMNKq66LiAwOgQ6rsM5ZiYgMCoEOq1AIdQOKiAwCwQ4rvSlYRGRQ8CCsEl2FiIj0t4CHlaYBRUQGgx6FlZnNMbMyMys3s68fY58SM1thZmvM7K99W2bXQnqflYjIoJDU3Q5mFgZ+BlwBVAJLzGyhc25th31ygZ8Dc5xz281sZD/VewRNA4qIDA49GVnNAsqdc5udc83AAuDaTvv8HfC4c247gHNuT9+W2TVNA4qIDA7WXTedmd1AbMT02fjtTwDnOedu77DPT4FkYCowBLjXOffbLo51C3ALQF5e3swFCxb0qvhHypp5cVszv7wyq1fHSaS6ujqysoJZf5BrB9WfSEGuHVR/f5o9e/ZS51xx5+3dTgMC1sW2zgmXBMwE3gOkA6+b2RvOuQ1HfJJz84H5AMXFxa6kpKQHD39sixvXE926id4eJ5FKS0sDW3+QawfVn0hBrh1UfyL0JKwqgaIOtwuBnV3ss885Vw/Um9nLwFnABvpRWFcKFhEZFHpyzmoJMNHMxptZCjAXWNhpn6eAS8wsycwygPOAdX1b6tFChhosREQGgW5HVs65iJndDjwPhIH7nXNrzOzW+P3znHPrzOw5YBWxnof7nHOr+7NwAIuPrJxzmHU1WykiIj7oyTQgzrlngGc6bZvX6fYPgB/0XWndC4diARV1EFZWiYh4K/ArWAC06p3BIiJeC3ZYtY+sFFYiIj4LdljFz1Mpq0RE/BbwsIr936q0EhHxWsDDStOAIiKDgR9hpQYLERGvBTqsOraui4iIvwIdVm3nrDQNKCLit0CHlWkaUERkUAh0WGkaUERkcAh0WKl1XURkcAh4WGkaUERkMPAirDSwEhHxW7DDKl69pgFFRPwW7LDSChYiIoOCH2Glc1YiIl7zI6yUVSIiXgt0WIXj1WsaUETEb4EOq7YVLHSlYBERvwU6rMJqXRcRGRQCHVZqXRcRGRwCHVam1nURkUEh0GH1zjSgwkpExGeBDqtQe4NFggsREZF+FeywUuu6iMigEOyw0jkrEZFBwY+w0jSgiIjXAh1WWsFCRGRwCHRYta9gobASEfFaoMNKresiIoNDoMNK56xERAaHQIdVPKs0DSgi4rlAh1U4pGlAEZHBINBhpRUsREQGh4CHVex/ta6LiPgt2GEV0goWIiKDQbDDSsstiYgMCoEOq7Ba10VEBoVAh5Va10VEBodAh1VIresiIoNCoMOqfRpQWSUi4rVAh1Vb63qr0kpExGvBDitNA4qIDArBDqv2FSwUViIiPutRWJnZHDMrM7NyM/t6F/eXmFm1ma2I//tW35d6tHdWsHg3Hk1ERBIlqbsdzCwM/Ay4AqgElpjZQufc2k67vuKce38/1HhMWsFCRGRw6MnIahZQ7pzb7JxrBhYA1/ZvWT2jFSxERAaHbkdWQAFQ0eF2JXBeF/tdYGYrgZ3AXc65NZ13MLNbgFsA8vLyKC0tPeGCO2pqjYVUefkmSqMV3ew9MNXV1fX6eUiUINcOqj+Rglw7qP5E6ElYWRfbOg9llgFjnXN1ZnYN8CQw8ahPcm4+MB+guLjYlZSUnFCxnTW2tMKLzzF2/ARKSk7r1bESpbS0lN4+D4kS5NpB9SdSkGsH1Z8IPZkGrASKOtwuJDZ6auecq3HO1cU/fgZINrPhfVblMbRNA6p1XUTEbz0JqyXARDMbb2YpwFxgYccdzCzfLJYcZjYrftz9fV1sZ+GQVrAQERkMup0GdM5FzOx24HkgDNzvnFtjZrfG758H3ADcZmYR4DAw170Lwx2tYCEiMjj05JxV29TeM522zevw8f8A/9O3pXXPzDA0DSgi4rtAr2ABscuEaGAlIuK34IcVup6ViIjvAh9WIdObgkVEfBf4sDKDqOYBRUS8FviwCqFzViIivgt8WJmmAUVEvBf4sAppGlBExHvBDys0DSgi4rvAh5WZWtdFRHznQViZVrAQEfFc4MMqBESjia5CRET6U+DDStOAIiL+C3xYaQULERH/BT6sDLWui4j4LvBhFdKq6yIi3gt8WGkFCxER/wU+rGJvClZYiYj4LPhhZWpdFxHxXeDDyszUui4i4rnghxVoBQsREc8FPqzUDSgi4r/Ah5UZtCqtRES8FviwUjegiIj/Ah9Wep+ViIj/Ah9Wal0XEfFf4MPK0MhKRMR3gQ8rrbouIuK/wIeVqXVdRMR7gQ+rEKaRlYiI5wIfVma6npWIiO8CH1ZawUJExH+BDytDK1iIiPgu+GGlbkAREe8FPqxCBsoqERG/BT6sDHQ9KxERzwU+rPSmYBER//kRVmqwEBHxWuDDKrY2YKKrEBGR/hT4sAqZVrAQEfFd4MNKK1iIiPgv8GGlFSxERPwX+LBS67qIiP+CH1YGTmElIuK1wIeVpgFFRPzXo7AyszlmVmZm5Wb29ePsd66ZtZrZDX1XYje1oYVsRUR8121YmVkY+BlwNTAFuMnMphxjv/8Enu/rIo9HK1iIiPivJyOrWUC5c26zc64ZWABc28V+XwT+AOzpw/q6FUKt6yIivkvqwT4FQEWH25XAeR13MLMC4DrgcuDcYx3IzG4BbgHIy8ujtLT0BMs9WkukhZZW65NjJUJdXZ1qTxDVnzhBrh1UfyL0JKysi22dhzI/Bb7mnGs162r3+Cc5Nx+YD1BcXOxKSkp6VuVxPFL2Amat9MWxEqG0tFS1J4jqT5wg1w6qPxF6ElaVQFGH24XAzk77FAML4kE1HLjGzCLOuSf7osjjia0NqGlAERGf9SSslgATzWw8sAOYC/xdxx2cc+PbPjaz3wB/fDeCKvZ4al0XEfFdt2HlnIuY2e3EuvzCwP3OuTVmdmv8/nn9XONxhUyt6yIivuvJyArn3DPAM522dRlSzrlP9b6snms7Q+ac43jny0REJLi8WMECNBUoIuKzwIdV22BKU4EiIv4KfFi1fQHqCBQR8Vfwwyo+slJWiYj4K/Bh1dZUoWtaiYj4K/Bh9U6DhcJKRMRXgQ+rtmZ1LWYrIuKv4IeVWtdFRLwX+LDSNKCIiP8CH1aaBhQR8V/gw0orWIiI+C/wYdW+goWmAUVEvBX4sGpfwUJDKxERbwU/rLSChYiI9wIfVlrBQkTEf4EPKy1kKyLiv8CHVfubgnXOSkTEW/6ElbJKRMRbgQ8rTQOKiPgv8GGlKwWLiPgv8GGl1nUREf8FPqza1gZU67qIiL8CH1ZadV1ExH/ehJVTWImIeCvwYWXxicDWaIILERGRfhP8sNI0oIiI9wIfVjpnJSLiv8CH1TtXCk5oGSIi0o8CH1YaWYmI+C/wYaUrBYuI+C/wYdX2Bah1XUTEX8EPq/ZLhCS2DhER6T+BDytNA4qI+C/wYRWKp5WmAUVE/BX4sGpfyFbTgCIi3gp+WKl1XUTEe4EPK10pWETEf4EPK42sRET8F/iwUuu6iIj/Ah9WulKwiIj/Ah9WuviiiIj/vAmrqLJKRMRbgQ+rd95npbQSEfFV8MNKK1iIiHivR2FlZnPMrMzMys3s613cf62ZrTKzFWb2lpld3Peldq1tGlAjKxERfyV1t4OZhYGfAVcAlcASM1vonFvbYbdFwELnnDOzM4FHgMn9UfBR9cX/V1aJiPirJyOrWUC5c26zc64ZWABc23EH51yde2ceLhN416JDVwoWEfFftyMroACo6HC7Ejiv805mdh1wDzASeF9XBzKzW4BbAPLy8igtLT3Bco/WUF8PGBvLN1Haur3Xx3u31dXV9cnzkAhBrh1UfyIFuXZQ/YnQk7CyLrYdNYxxzj0BPGFmlwL/Dry3i33mA/MBiouLXUlJyQkV25XnX/oL0MD4CRMouezUXh/v3VZaWkpfPA+JEOTaQfUnUpBrB9WfCD2ZBqwEijrcLgR2Hmtn59zLwKlmNryXtfWIqcFCRMR7PQmrJcBEMxtvZinAXGBhxx3M7DSL95Cb2TlACrC/r4vtilawEBHxX7fTgM65iJndDjwPhIH7nXNrzOzW+P3zgA8Df29mLcBh4KPuXUoPrWAhIuK/npyzwjn3DPBMp23zOnz8n8B/9m1pPaMVLERE/KcVLEREZMALfFgBhEOmaUAREY95EVYh0/WsRER85klYmVawEBHxmD9hpXlAERFveRJWal0XEfGZH2EV0jSgiIjP/AgrTQOKiHjNi7BS67qIiN+8CCu1rouI+M2LsDIzrWAhIuIxL8IqbEY0mugqRESkv3gRVpoGFBHxmxdhZVrBQkTEa16EVTik1nUREZ95EVZawUJExG9+hJVWsBAR8ZofYaVzViIiXvMkrFDruoiIxzwJK1PruoiIx7wJK61gISLiLy/CSgvZioj4zYuwChm0Kq1ERLzlRVhpBQsREb95EVZhvc9KRMRrXoSVWtdFRPzmSVhpZCUi4jOFlYiIDHh+hFVIC9mKiPjMj7DSyEpExGv+hJWGViIi3vIirLSChYiI37wIK61gISLiNy/CSitYiIj4zYuwCpuhrBIR8ZcXYRUKoetZiYh4zIuw0jSgiIjfvAirsFrXRUS85kVYhUwrWIiI+MyPsNIlQkREvOZHWGkaUETEa56ElaYBRUR85kVYhUOm1nUREY95EVZmhlNYiYh4q0dhZWZzzKzMzMrN7Otd3P8xM1sV//eamZ3V96UeW9i0kK2IiM+6DSszCwM/A64GpgA3mdmUTrttAS5zzp0J/Dswv68LPR4tZCsi4reejKxmAeXOuc3OuWZgAXBtxx2cc6855w7Gb74BFPZtmcenFSxERPxm3Z3rMbMbgDnOuc/Gb38COM85d/sx9r8LmNy2f6f7bgFuAcjLy5u5YMGCXpYPdXV1PF2RzF8rI8y7IrPXx3u31dXVkZWVlegyTkqQawfVn0hBrh1Uf3+aPXv2UudcceftST34XOtiW5cJZ2azgZuBi7u63zk3n/gUYXFxsSspKenBwx9faWkpY8aMxHZupy+O924rLS0NZN0Q7NpB9SdSkGsH1Z8IPQmrSqCow+1CYGfnnczsTOA+4Grn3P6+Ka9ntIKFiIjfenLOagkw0czGm1kKMBdY2HEHMxsDPA58wjm3oe/LPL6QzlmJiHit25GVcy5iZrcDzwNh4H7n3BozuzV+/zzgW8ApwM/NDCDS1Zxjf9EKFiIifuvJNCDOuWeAZzptm9fh488CRzVUvFvCZmpdFxHxmDcrWABaxUJExFNehFU4FAsrDa5ERPzkRVjFs0pTgSIinvIirNqmAdURKCLiJy/Cqm0aUFklIuInL8KqfRpQaSUi4iVPwkrTgCIiPvMrrNRgISLiJU/CKva/skpExE9ehFVORjIAm/fWJbgSERHpD16E1ZVT8slOS+LXr25NdCkiItIPvAirzNQkbpo1hmdX76LyYEOiyxERkT7mRVgBfPLCcZgZv319W6JLERGRPuZNWI3OTefqafk8/OZ26psiiS5HRET6kDdhBXDzxeOpbYzw9MqjLmQsIiIB5lVYzSjKJRwyKnTeSkTEK16FlZmRnZZE9eGWRJciIiJ9yKuwAshJT6bmsM5ZiYj4xLuwyk5P1shKRMQz3oVVjsJKRMQ73oVVdnoyNY0KKxERn/gXVmnJ1GhkJSLiFe/Cqm0a0OnaViIi3vAyrFpaHY0t0USXIiIifcS7sMpOTwJQk4WIiEe8C6uc9Ni1rRRWIiL+8Das1BEoIuIP78IqOy0+smpQWImI+MK7sNI0oIiIf7wNK00Dioj4w7uwGpKmbkAREd94F1ZJ4RBZqUlaeV1ExCPehRWga1qJiHjGz7DSyusiIl7xMqxytPK6iIhXvAyr7HStvC4i4hMvw0oXYBQR8Yu3YaWRlYiIP7wMq+y0ZOqbW2lp1WVCRER84GVY5cQvE6LRlYiIH/wMq4y2JZf0xmARER94GVbtK69rZCUi4gUvw0orr4uI+MXrsNI5KxERP/QorMxsjpmVmVm5mX29i/snm9nrZtZkZnf1fZknJlsjKxERryR1t4OZhYGfAVcAlcASM1vonFvbYbcDwB3Ah/qjyBOlaUAREb/0ZGQ1Cyh3zm12zjUDC4BrO+7gnNvjnFsCDIh0SE0KkRIOaX1AERFP9CSsCoCKDrcr49sGLDPT+oAiIh7pdhoQsC62uZN5MDO7BbgFIC8vj9LS0pM5zBHq6uq6PE6ya2bjtp2Ulh7o9WP0p2PVHwRBrh1UfyIFuXZQ/YnQk7CqBIo63C4Edp7Mgznn5gPzAYqLi11JScnJHOYIpaWldHWc/LWvkpaSREnJeb1+jP50rPqDIMi1g+pPpCDXDqo/EXoyDbgEmGhm480sBZgLLOzfsnpPK6+LiPij25GVcy5iZrcDzwNh4H7n3BozuzV+/zwzywfeArKBqJl9GZjinKvpv9KPb1hmCut31Sbq4UVEpA/1ZBoQ59wzwDOdts3r8HEVsenBAeO0kVk8vmwH1Ydb2lvZRUQkmLxcwQJgcv4QADbs1uhKRCTovA2rSfnZAKyvUliJiASdt2E1OieNIWlJlFUl7LSZiIj0EW/DysyYlDeEMo2sREQCz9uwApiUP4T1VbU4d1LvYRYRkQHC67CaPCqb2sYIu6obE12KiIj0gt9hFe8I1FSgiEiweR1Wp+fFwmp9VS3RqOOOh5fz8JvbE1yViIicKK/DKic9mdE5aZRV1fDE8h0sXLmTJ5fvSHRZIiJygnq0gkWQTcofwoqKQ7y6aT8Aa3fV4JzDrKvF5EVEZCDyemQFsTcHb93fwN7aJj5aXERtY4TKg4cTXZaIiJwA78OqrcnixuJC5s6KXelk7S69UVhEJEi8D6uSSSP42Hlj+NqcyUzOzyZksE5hJSISKN6fs8rNSOG7101vvz1ueCZrdyqsRESCxPuRVWdTRmVrGlBEJGAGX1iNzqby4GFdRVhEJEAGX1iNil06ROetRESCQ2ElIiID3qALqxFDUhmelZLwJoumSCv/+PsV7GmIJrQOEZEgGHRhZWac0cMmi13Vh2mKtPZLHRt31/HE8h2s3Ns/xxcR8cmgCyuINVls3F1Hc+TYo5pIa5Q5P32Fe55Z3y817K6JXbbkUKOutSUi0p3BGVajsmlujbJpb90x99m6v4Hqwy38YVkljS19P/rZXdMEwMEmhZWISHcGbVjB8Zss2q6BVdsY4bnVVX1eQ/vIqknnrEREujMow2r88ExSk0LHbbJYX1VDyKAgN53fL6no8xrawuqgpgFFRLo1KMMqKRxicv6Q4zZZrK+qZfzwTG6aVcTrm/ezbX99j4//ysa9PL6s8rj7vDOyUliJiHRnUIYVxJos2q5t1ZX1VTVMHpXNDTOLCBk8+taR4fP7Jdt5ce3uLj/3hy9s4F+fXnvMY8M756wOR6C+KXKSX4WIyOAwaMPqjFHZHGpoYVd141H31TVFqDhwmMl5Q8jPSeOy00fw+LLK9vBxznHPs+v5RWn5UZ9b3xRh9Y5qqg+3UHHg2NfN2l3TSFZqUvvHIiJybIM2rI7XZLFhd6y5YnJ8n9mTR7KzurH9oo3b9jdwqKGFDbvrjho9Ldt+kNZobNvKykNdPnZzJMr++mamFcSOX6WwEhE5rkEbVm1B1NZkUXGggS37Yuel1u+Kh1X8wo3njBkKxIIIYEXFISA2AtvZaWT25pYDhENGSjjE2zuqu3zsvXWxKcAzC3MB2BOfEhQRka4N2rDKSk1i3CkZrN1VQ31ThBvmvcZH5r1OQ3OEsqoaslKTKMhNB2KhlZESZtm2I8MKYEO8xb3N4i0HmDY6mzNGZ7PqGCOrqnjAnVmYE7utkZWIyHEN2rCCd5os/vvP5eyuaWJfXRMPvLaNdVW1nJ6XRShkQKx7cEZRLkvjI6vlFYfaR11lu98Jq8aWVlZUHGLW+GGcVZjD6h01RKNHN1nsiYfThOFZpIV1zkpEpDuDOqzOyM9m2/4GfvW3zdwws5DZk0Yw76+bWLerpn2asM3MsUNZt6uWQw3NrNtZw2WnjyA/O+2IkdWqymqaI1FmjT+F6QU51DVF2Lzv6Jb3tnDKy05laJodN6yefXsX9zy7rk++3taoo6FZnYciEjyDOqymjI4FUlpSmK/NmcydV06i+nALtY2R9pFTm3PGDqU16nj4zQqaW6PMKMrl9PwhR4ys3tyyH4Bzxw1tPx/19o5DNEei3Pi/r3PfK5sBqKppIjlsDM1IITfV2tvYO4u0Rvl/f1rH//51c3vTR2/M++smZv+wtL0BJAgirVGeXL4jUDWLSN8b1GF1ZmEuKUkh7rpqEiOGpDKtIIdrpucDMDn/yJHVOUWxJovfvr4VgBljcpmUl8XGPXVEWmNLJi3ecoDJ+UPIzUjhtJFZpCeHWVlRza9f3cKbWw7w+LIdQGwacOSQNEIhY2haqP0cVmcvrdvDjkOxDsSHFm/v9df7xub97K5pal9KKghKy/by5d+v4C/r9yS6FBFJoEEdViOGpLL0n9/LJy8c177tG9ecwacvGseMotwj9s3JSGbiyCx2VTcyckgq+dlpnJ43hOZIlG0HGmiKtLJ020FmjR8GQDhkTCvI5uWNe7l30UZSkkKsq6rhUEMzu2sbyctOBSA31dhT29jlG4h/89oWCnLTed/0UTzeywV1nXPt3YnLKw6e9HHebW1vLThWZ6WIDA6DOqwAhqQlH3G7cGgG3/7AVFKSjn5qZo6Nja5mFOViZu2jrw1VtTz6ViUNza1cNTW/ff/pBbls3ltPJOq457rpOAdvbD7A7pom8rLTABiaZrS0Og7UNx/xWOuranhj8wE+ccFYPn7+WGoaI/xx1a6T/jp3HDrMoYYWAJZtO3TSx3m3rY9Pf65WWIkMaoM+rE7EOW1hNSYXgNNGZmEGa3bWMO+vm5hRlMuFp57Svv9ZRbHW9FsvO5UPnDWa9OQwr2/ax+7qxvawyk2NdRx2Pm/1wGtbSUsOMffcIs6fMIwJIzJ5aPG2k6697Y99fnZaoEZWbVOWGlnB4eZWKg40JLoMkYRQWJ2ASyeOYMKITN4zOQ+A9JQwY4dl8MDrW6k8eJgvXn4aZta+/1VT8/n3a6fy+ZJTSUkKUTxuKH8u20NtU+SIkRUc2b6+49BhHl+2gw/NKCA3IwUz4+9mjWHZ9kPHvaxJR6+W7+PyH5ZSeTD2x231jhrCIePG4kI2763nUENzN0c4eY0trTz79q4u2/ZPRFOklS376snNSGZPbVN7y/9g9dOXNnDVT1+mOj5CFhlMFFYnID8njT/fWcKkDp2Cp+cNobYxwhmjsrl88sgj9k9LDvOJC8aRlhwG4IJTT2lfLzA/J3bOamjq0WH1H39ahxncfvlp7dtumFlIenKY+17Z0m2d++qa+NKCFWzeV88T8aaO1TurmTgyi/PjI7/lHd7Y3Nfuf3ULtz24jIfe7F1TSPmeOlqjjmvPGg1odPXn9XtoaG7l6VU7E12KyLtOYdVLbcF1++wjR1VduWDCO1OEeUNiI6uceFi1rWLxWvk+/vT2Lm677DQKh2a075+bkcJHzy3iqRU72FV97AVyo1HHnY+spKaxhQnDM3l61U6cc6zeUc20ghzOKswlZLB8W/9MBTZHojzw2lYAfvB82VHn4k5E2xTgdecUYja4w2pX9WE27old2frRpe9cAaAp0tovV7IWGWgUVr10Y3ERd115OnOm5Xe77/SCnPaV1kfGpwGTQsbwrBR21zRxuLmV7zy9hsKh6XzusglHff7NF4/HAff/revR1YH6Zv7tj2v564a9/Mv7Yl2NG3bX8fLGfeyra2ba6GwyU5OYlJ/dPrJ6euVOnn375Bs3OvvT2zvZXdPEN685g/qmCN9/bv1JH6usqpaUcIipo7OZMDyT1Tt6NgXqo1c27gNiI+yVFYfYuLuWxojj/f/1N+bOf6PXU64iA53CqpeKhmVw++UTCYeOP6qC2LJNba3t+Tlp7dvzstP4w9JKpnz7OTbsruNf3j+lfeqw82O9/8xRPLR4O9WH3zlv0dIa5d+eXsuF31vEb17bytxzi/j4+WO5evoowiHje8/GAmNaQazh45wxuazYfoj/XrSRLz68nNseXMb3n1vf6z94zjnue2ULE0dm8dlLxvPpi8bx+7cqWL795EZx66tqOXVkFsnhENMLct71jsBXy/fx4V+8xsY+eEN2b72ycR/Ds1L52pzJJIWMx5ZW8ru1zWzcU8eKikP8oZuLfXa2YXct//7HtZSW7aE5Eu2nqmWgaY5EeXDxNuqag/fiRmH1Lpt7bhFXTc1rH2EBfPKCcVw5NY87Lp/IA5+ZdUT7e2e3XDqB+uZW/ufPG3HOEY06vvLoSu5/dQsfOHM0L/7jpXzvw2diZgzPSuXCU09h3a4azN5ZseOcMUOpbYrwoxc3cN3ZBdw0aww/L93EFx5a1qt1Ct/YfIA1O2v4zMXjMTO+9N7TGTkklW88sZqW+Bunq6ob+cKDy3r0xuSyqtr2lUSmFeRQVdPI3tqer1D/1tYD/OiFMj7zmyV85dGVNEV6Pl32avk+PvObJSzddpA7H13Z/sbvRIhGHa+W7+PSicMZMSSV2ZNH8uvXtvLqzgh3XH4aM4py+cHzZT2+iGc06rjr0ZX86m9b+NSvl1D8/17kn36/ghfWVGlK0XP3v7qFbz6xmt+X9V+DVX9J6n4X6UtXTs3nyk5hdOO5Rdx4blGPPn/q6ByuP7uAX76yhfI9dRQMTefJFTv5ylWT+MLs047a/wNnjeaVjfs4dUQWGSmxb/d5E4aRnhzmxuJCvv2BqZjBhOGZ/Odz61m0fg83nVvEmFMy2VPTSENzK1lpSSSHjE376tm4u5b8nHSuPWs0GZF3Xp21Rh0/eWkDwzJTuO7sAiC2sv2/XTuNz/1uKfNf3sxnLxnPbQ8uZfn2Q2zZV89Tt19Ecrjr10vVDS1U1TS2nxOcHh8Vrt5RzexOjSxdeW51Fbc9uBQDxg/P5M/r9+CAH9xwZrfnFl/btI+bH1jCuFMy+dj5Y/jWU2uY/8pmPl9yWvubt7s7xuLN+9m6v566plaGZ6XwvumjSDrG19qVA/XNPLF8Bx8pLmT7/gYO1DdzyenDAfjIzEJeXLubSUND3PGeiVw2aSQf/sVrzPvrJu68ctIRx4m0RvnDskqeWL6Dr86ZzDljhvKHZZWsqqzme9dPZ3hWKs+tqeLFtbt5fPkOpozK5vHPX9jlyH4geeStCl7esJfmSJThQ1L5xjVnHPEC8GRFo659AWuITZO/tmkfd19zBtmd3pMZNDsPHea/Fm0kPTnM33ZE2LC7ltPzhnT/iQNEj767ZjYHuBcIA/c5577X6X6L338N0AB8yjm3rI9rlbgf3XgWZxXl8h/PrKMpEuVTF47j8yWndrnvVVPz+ecnVrf/sYfYG5+Xf+uKI/4g/cOlE5gzLZ+f/aWcBxdvJxJ1pCSFyEgJU9cYIRJ1FA1L5/SRsfUQ73x0JZnJMHLiQWaOHcovSst5c8sBvn/DmUcc96qp+VwzPZ97F23k7cpqlm8/xE2zinj4zQp+GQ+Arqyvip2fagurqfH6F2850G1YLd12kC8tWM5Zhbn87uZZDElL5icvbuDeRRsZPzyT3IxkHnxjO9k0ctEl0SMCc+PuWj7326WMGZbBQ/9wHsMyU3h9035++uJGqqobKS3by6GGZm4rOY1PXzTuqD/qFQca+Nen1/DSuiOXh7r3pY18+YrTuXJKHmnJYeqaIvx+SQXrd9Xwz++bQk7GO38Idx46zCd+tZhNe+tZ8Ob29qnji06LhdV7zsjjnuunk3lwE0nhEDPHDuWDZ41m/submTl2KCWTYs/PonW7+e4z69i8t57UpBCfuG8x//Oxc/j+82WcPSaXG4uLCIWM907Jo6U1ylMrdnLXoyv5yUsbuPvqM477HHfn7cpq1lfVcPX0UUeFSMWBBt7cFeEy57oN/a68sKaKrz62ilE5aeSkJ7No/R4qDx7mV58sPuJ76Zyj8uBhCoem9+hx/u+Nbfzg+TJ+8tGzuHxyHisrDnHnIytpbo2yePMB5v/9TE4beew/7s45Fm85QFMkyqUTh5/U19Yd5xxRR7enHRqaI+0vTtt890/raI06Hr31Aj4671W+/1wZ932yuFf1NEVaSU16d17YWFfL/Byxg1kY2ABcAVQCS4CbnHNrO+xzDfBFYmF1HnCvc+684x23uLjYvfXWW72rHigtLaWkpKTXx0mU3tRfvqeWN7ccZO65RUe8GuzstU37GDMs44juwuNpew9WTnoyZoZzjtaoax8ZOOdYuu0gX/jtG9RGYq/uf/B8Ge+bPop758446pd0T20jV/z4ZaoPt/C5Sydw9zVn8PkHl/LSuj08c8clnDYy66gafvv6Vr711Bpev/tyRuXErit24/++zptbDnDe+GFcf04BFQcOs2V/PdNG5zBnWj6pSSEWrdvNj1/cQE56Mn+47UJOyYq9RSAadXzhoWU8u7oKgAkjMtm8t55rpufzX3PPJikcYn9dEx/6+ascbo7y1O0XtV/PbF9dE1f95GVqGyNceNopGPCXsr3kZ6dRNCydxpYoTZFWmiJRdlU3khQyvvzeiVwzfRRDUpNZvGU/P3yhjA2760gOG1NH57Bpbx21jZHY9OyobH53cywY1+ys5h8eeIvaxghfeu9E/mvRRmriCys/9+VLj3iOOv7s7Klt5JP3L6GsqoY7r5xEWVUtC1fu5LSRWXzlqknMKMrl7375Bpv2xq4C8OQXLjpqSTGAux9fxYIlFTz6uQsoHhcLyb21Tby4djcHG5r5yMzC9uagY3lx7W5uf2gZTZEoGSlhrp0xmptmjWF6QQ6lZXv50oLl1DRGuGFmIfdcP73L0XVzJMpL63YzJC2J8yec0r7P1n31fOC//8a44Zk8eusFpCWHeWRJBV/9wyo+fE4hP/xIbORc3dDC1x9fxbOrq/jgWaP57nXTjlqt5ojnsmwPn/nNEpLDIZyDe66fzo9f3ADAtz8whW888TaHm1u5+eLxfPyCsaxd+kb7c1/fFOGldbv51d+2sKoydl61eOxQvjpnMqNy0mhujbJmZw2vle+jvrmV2y47tX1K/kQs3XaA2x9aTlMkyodmFHDDzMKjjtPY0sq/Pr2WBUu2c+tlp/JPV5zefo7zK4+t4s4rTueL75nIXb96gcc2tvDI5y5ofzF0LK1Rx+ub9vPHVTsZc0oGN188npRwiAVLKvjOwjXMnjSS7143rf13rbfMbKlz7qgU7UlYXQB8xzl3Vfz23QDOuXs67PO/QKlz7uH47TKgxDl3zDYzhVVMkOt/8vk/M29dEuuraikals6f7rjkmFMlpWV7eHnDPr5xzWSSwqH2AKtvijB1dDbTC3MYnpVKVmoSW/fX85f1e6ltbGHlt69sD7/GllYeWrydeX/dxJ7aJsIhIz87rX2x3zYTR2bxy78vZtzwzCO2NzRHuP9vWzh/winMHDuUbzzwEg+vb+bi04ZTNCydpdsOsm1/AwtuOZ+z41eHbnOwvpmksLX/wXtt0z5++fJmGluipCWHSE0Kk5YcYlhmKp+9ZDyj40HXpjXqeHnjXt7YvJ9l2w6Sl53GzReP59DhFj73u9hILis1iRUVhzglM4UHPjOLaQU5bN5bxz8+spIPzRjNpy8af+Rz2ulnp6E5wp2PrOTZ1VUkh40vXj6RWy87tX3psL21TfzDb99iRlEu3/ng1C6/T3VNEa6+92VaIo4po7PZVd3I+qoa2v5MJIeND5w1mukFOZySlUp6cpioc+2v+Lfsq+dHL5QxvSCHu66axNMrd/L0yl0cbmnl1BGZbN5Xz+T8bMamHua5rS1cevoIPjKzkHDICJmRFDIqDjZw3ytb2r+vQ9KSOHfcMHLTk1lRcYgDDc388YsXH/Hi696XNvKTlzYwZlgGM8cO5c0tB9hd08jV00fxp1U7KRqWwacuHEduRjKZKUmxxwsZYTPqmyJ85bFVjBmWwa8+VcznfreUVZXVpIRDPHbbBZxZmMvOQ4f51lNrWLR+N0khY9wQY/zoETRFory+eT/NkSjjh2dyy6UTcA5+/GIZ++qOPC80JC0JA2qbIlw3o4CpBTkkh43kcIikkJGSFCIpFCI5bEfUFw4Zq3dU84PnyygYms6UUdksWreH5tYoU0Zlc/05BRQOTae51fHzv5SzvqqWWeOH8eaWA5w9JpdIa2xd0GkF2Tx2a2yK9/lFf+Fbi1vZV9fMmYU5TC/I4UB9M1XVjdQ2Rjjc0kqkNUo4bNQ3tXKgvpmMlDANza1MGJHJGaOy+dOqXZxZmMP6XbUMSUviP66fftzz7T3Vm7C6AZjjnPts/PYngPOcc7d32OePwPecc3+L314EfM05d8w0UljFBLn+0tJSZsy6kB+9sIGbZo054VeL66tqWLhiJ0u3HWTdrhpqGmMNAlmpSUwvyOG6swu6PJfX2BJbdqhoWAZpyWF2HDrMC2uqiLQ6Zk8eyakjMns0BVNaWkp5eAz3LtpIWnKYoRnJ3HnlpD75hTsRr5bv45bfvkXB0HQ+MrOI688p6NGr1K5+dqJRx8KVO5k6OpuJJ3k+Yum2A9z9+Nskh0MMz0rlrKJc5kzNJyMlzP2vbuHRtyo5fJxGjEtPH8EvPnYOmfHpv5rGFp5asZMnl+9gUv4Q/uV9U1j82ivsyTyVu594u8vLv8wcO5TbZ59GJOp4fk0Vq3dUUxdvILnn+ulcMnHEEfs75/j9kgr+UraHpdsOkpuRwo8+EpsuX7L1AF9esOKoFzUd5WWn8uQXLmJUTjrVh1v4xuNvc+XUPK6dUXDEflv21fPb17fy+rrtuORMos5xycQRXDElj1njh7VPz9U1RXhxbRWt0djbU8YNz2Ta6Gzqm1r5eWk5v35t6wl3Yb73jDx+dONZ5KQnc7C+madX7eSxpZXtozmAoRnJ/OSjMyiZNJKFK3fyjcffZmhmMl96z+l8aMbo9tmR0tJSxk47l8eXVfJq+T427q7jlKwU8rJjU6sZKWGSwiGi0dhU7ezJI3jvGXm8sXk/33pqDRUHG7jj8onc8Z6JlO+p458eWUFSyHj88xf1qDP6eHoTVh8BruoUVrOcc1/ssM+fgHs6hdVXnXNLOx3rFuAWgLy8vJkLFizo1RcFUFdXR1bW0dNIQRHk+vu69tao43AEMpIh1A/z/Z0NpOe+JepIsu4bNzpKVP1R56hvgZomR0vUYQZGrPawQX6mdfv9a6u9pslR2xIblcVGaLHR2+hMO+lzPq6Lc2FR56hrgYYWR2PEEQWiDpyL/V+QFSIr5d177iNRR1MrtLrYz30kGvs4Eo3d17m+pBCMzwl1+bzubYjS2Br7HpySbqQnvbPP4YgjJXT0Oa7e1N/c6jjY6MjLfGf6NhJ11DU7ctN632A+e/bsLsOqJw0WlUDHl7eFQOf1XnqyD865+cB8iI2s+mJEEeSRCQS7/iDXDqo/kYJcO6j+ROhJDC4BJprZeDNLAeYCCzvtsxD4e4s5H6g+3vkqERGRE9HtyMo5FzGz24HnibWu3++cW2Nmt8bvnwc8Q6wTsJxY6/qn+69kEREZbHr0Pivn3DPEAqnjtnkdPnbAF/q2NBERkRgttyQiIgOewkpERAY8hZWIiAx4CisRERnwFFYiIjLgKaxERGTAU1iJiMiAp7ASEZEBT2ElIiIDnsJKREQGPIWViIgMeAorEREZ8Lq9+GK/PbDZXmBbHxxqOLCvD46TKEGuP8i1g+pPpCDXDqq/P411zo3ovDFhYdVXzOytrq4qGRRBrj/ItYPqT6Qg1w6qPxE0DSgiIgOewkpERAY8H8JqfqIL6KUg1x/k2kH1J1KQawfV/64L/DkrERHxnw8jKxER8ZzCSkREBrzAhpWZzTGzMjMrN7OvJ7qe7phZkZn9xczWmdkaM/tSfPswM3vRzDbG/x+a6FqPxczCZrbczP4Yvx2k2nPN7DEzWx//HlwQsPr/Mf5zs9rMHjaztIFcv5ndb2Z7zGx1h23HrNfM7o7/LpeZ2VWJqbq9lq5q/0H8Z2eVmT1hZrkd7hswtcfrOar+DvfdZWbOzIZ32Dag6j+WQIaVmYWBnwFXA1OAm8xsSmKr6lYEuNM5dwZwPvCFeM1fBxY55yYCi+K3B6ovAes63A5S7fcCzznnJgNnEfs6AlG/mRUAdwDFzrlpQBiYy8Cu/zfAnE7buqw3/nswF5ga/5yfx3/HE+U3HF37i8A059yZwAbgbhiQtUPX9WNmRcAVwPYO2wZi/V0KZFgBs4By59xm51wzsAC4NsE1HZdzbpdzbln841pifywLiNX9QHy3B4APJaTAbphZIfA+4L4Om4NSezZwKfArAOdcs3PuEAGpPy4JSDezJCAD2MkArt859zJwoNPmY9V7LbDAOdfknNsClBP7HU+Irmp3zr3gnIvEb74BFMY/HlC1wzGfe4CfAF8FOnbVDbj6jyWoYVUAVHS4XRnfFghmNg44G1gM5DnndkEs0ICRCSzteH5K7Ac92mFbUGqfAOwFfh2fxrzPzDIJSP3OuR3AD4m9It4FVDvnXiAg9XdwrHqD9vv8GeDZ+MeBqN3MPgjscM6t7HRXIOqH4IaVdbEtED34ZpYF/AH4snOuJtH19ISZvR/Y45xbmuhaTlIScA7wC+fc2UA9A2vK7Lji53auBcYDo4FMM/t4YqvqU4H5fTazbxKb0n+wbVMXuw2o2s0sA/gm8K2u7u5i24Cqv01Qw6oSKOpwu5DYtMiAZmbJxILqQefc4/HNu81sVPz+UcCeRNV3HBcBHzSzrcSmXC83s/8jGLVD7Oel0jm3OH77MWLhFZT63wtscc7tdc61AI8DFxKc+tscq95A/D6b2SeB9wMfc++8QTUItZ9K7IXOyvjvcCGwzMzyCUb9QHDDagkw0czGm1kKsROECxNc03GZmRE7Z7LOOffjDnctBD4Z//iTwFPvdm3dcc7d7ZwrdM6NI/Zc/9k593ECUDuAc64KqDCzSfFN7wHWEpD6iU3/nW9mGfGfo/cQO+cZlPrbHKvehcBcM0s1s/HARODNBNR3TGY2B/ga8EHnXEOHuwZ87c65t51zI51z4+K/w5XAOfHfiwFffzvnXCD/AdcQ68rZBHwz0fX0oN6LiQ2vVwEr4v+uAU4h1hm1Mf7/sETX2s3XUQL8Mf5xYGoHZgBvxZ//J4GhAav/X4H1wGrgd0DqQK4feJjY+bUWYn8cbz5evcSmqTYBZcDVA7D2cmLndtp+d+cNxNqPVX+n+7cCwwdq/cf6p+WWRERkwAvqNKCIiAwiCisRERnwFFYiIjLgKaxERGTAU1iJiMiAp7ASEZEBT2ElIiID3v8HgoWGiLxB7RMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7)) \n",
    "plt.grid() \n",
    "plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "#plt.ylabel('Loss') \n",
    "#plt.xlabel('Epochs') \n",
    "#plt.legend(['Training','Validation'], loc='upper right') \n",
    "#plt.savefig(\"loss_curve.pdf\") \n",
    "#plt.show()\n",
    "#plt.figure(figsize=(5,5)) \n",
    "#plt.ylim(0,1.1) \n",
    "#plt.grid() \n",
    "#plt.plot(history.history['acc'])\n",
    "#plt.plot(history.history['val_acc'])\n",
    "#plt.ylabel('Accuracy') \n",
    "#plt.xlabel('Epochs') \n",
    "#plt.legend(['Training','Validation']) \n",
    "#plt.savefig(\"acc_curve.pdf\") \n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 418307,
     "status": "ok",
     "timestamp": 1602478822219,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "HKSPxOqckkD3"
   },
   "outputs": [],
   "source": [
    "# load best weights\n",
    "model.load_weights(\"best-model.hdf5\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 418301,
     "status": "ok",
     "timestamp": 1602478822220,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "tzGuqZILkkD5",
    "outputId": "58b28fd2-e2a8-47a5-94bd-3bb222491aa0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48717, 24, 24, 3, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = Xtest.reshape(-1, windowSize, windowSize, K, 1)\n",
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 418293,
     "status": "ok",
     "timestamp": 1602478822221,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "FIhcrDHQkkD7",
    "outputId": "301bc50b-063d-4ad4-b84e-96658ec5bfee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48717, 16)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest = np_utils.to_categorical(ytest)\n",
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "executionInfo": {
     "elapsed": 427183,
     "status": "ok",
     "timestamp": 1602478831122,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "x9gnEB8wkkD-",
    "outputId": "38e44cce-3f72-40f7-b8e4-5914a2294f69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1808\n",
      "           1       1.00      1.00      1.00      3354\n",
      "           2       1.00      1.00      1.00      1779\n",
      "           3       0.99      1.00      1.00      1255\n",
      "           4       1.00      1.00      1.00      2410\n",
      "           5       1.00      1.00      1.00      3563\n",
      "           6       1.00      0.99      1.00      3221\n",
      "           7       1.00      1.00      1.00     10144\n",
      "           8       1.00      1.00      1.00      5583\n",
      "           9       1.00      1.00      1.00      2950\n",
      "          10       1.00      1.00      1.00       961\n",
      "          11       1.00      1.00      1.00      1734\n",
      "          12       1.00      1.00      1.00       825\n",
      "          13       1.00      1.00      1.00       963\n",
      "          14       1.00      1.00      1.00      6541\n",
      "          15       0.99      1.00      0.99      1626\n",
      "\n",
      "    accuracy                           1.00     48717\n",
      "   macro avg       1.00      1.00      1.00     48717\n",
      "weighted avg       1.00      1.00      1.00     48717\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred_test = model.predict(Xtest)\n",
    "y_pred_test = np.argmax(Y_pred_test, axis=1)\n",
    " \n",
    "classification = classification_report(np.argmax(ytest, axis=1), y_pred_test)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 427171,
     "status": "ok",
     "timestamp": 1602478831123,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "M8Z-62eCkkEA"
   },
   "outputs": [],
   "source": [
    "def AA_andEachClassAccuracy(confusion_matrix):\n",
    "    counter = confusion_matrix.shape[0]\n",
    "    list_diag = np.diag(confusion_matrix)\n",
    "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    average_acc = np.mean(each_acc)\n",
    "    return each_acc, average_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 427165,
     "status": "ok",
     "timestamp": 1602478831124,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "Jw2j7mjQkkEC"
   },
   "outputs": [],
   "source": [
    "def reports (X_test,y_test,name):\n",
    "    #start = time.time()\n",
    "    Y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    #end = time.time()\n",
    "    #print(end - start)\n",
    "    if name == 'IP':\n",
    "        target_names = ['Alfalfa', 'Corn-notill', 'Corn-mintill', 'Corn'\n",
    "                        ,'Grass-pasture', 'Grass-trees', 'Grass-pasture-mowed', \n",
    "                        'Hay-windrowed', 'Oats', 'Soybean-notill', 'Soybean-mintill',\n",
    "                        'Soybean-clean', 'Wheat', 'Woods', 'Buildings-Grass-Trees-Drives',\n",
    "                        'Stone-Steel-Towers']\n",
    "    elif name == 'SA':\n",
    "        target_names = ['Brocoli_green_weeds_1','Brocoli_green_weeds_2','Fallow','Fallow_rough_plow','Fallow_smooth',\n",
    "                        'Stubble','Celery','Grapes_untrained','Soil_vinyard_develop','Corn_senesced_green_weeds',\n",
    "                        'Lettuce_romaine_4wk','Lettuce_romaine_5wk','Lettuce_romaine_6wk','Lettuce_romaine_7wk',\n",
    "                        'Vinyard_untrained','Vinyard_vertical_trellis']\n",
    "    elif name == 'PU':\n",
    "        target_names = ['Asphalt','Meadows','Gravel','Trees', 'Painted metal sheets','Bare Soil','Bitumen',\n",
    "                        'Self-Blocking Bricks','Shadows']\n",
    "    \n",
    "    classification = classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names)\n",
    "    oa = accuracy_score(np.argmax(y_test, axis=1), y_pred)\n",
    "    confusion = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
    "    each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
    "    kappa = cohen_kappa_score(np.argmax(y_test, axis=1), y_pred)\n",
    "    score = model.evaluate(X_test, y_test, batch_size=32)\n",
    "    Test_Loss =  score[0]*100\n",
    "    Test_accuracy = score[1]*100\n",
    "    \n",
    "    return classification, confusion, Test_Loss, Test_accuracy, oa*100, each_acc*100, aa*100, kappa*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 445851,
     "status": "ok",
     "timestamp": 1602478849818,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "wiez8wEtkkEE",
    "outputId": "9955427d-ee60-4060-b1eb-9e79bbf5b67f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523/1523 [==============================] - 26s 17ms/step - loss: 0.0041 - accuracy: 0.9994\n"
     ]
    }
   ],
   "source": [
    "classification, confusion, Test_loss, Test_accuracy, oa, each_acc, aa, kappa = reports(Xtest,ytest,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 445840,
     "status": "ok",
     "timestamp": 1602478849819,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "kR-idaI8J5bl"
   },
   "outputs": [],
   "source": [
    "classification = str(classification)\n",
    "confusion = str(confusion)\n",
    "file_name = \"classification_report.txt\"\n",
    "\n",
    "with open(file_name, 'w') as x_file:\n",
    "    x_file.write('{} Test loss (%)'.format(Test_loss))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Test accuracy (%)'.format(Test_accuracy))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Kappa accuracy (%)'.format(kappa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Overall accuracy (%)'.format(oa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Average accuracy (%)'.format(aa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{}'.format(classification))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{}'.format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 445833,
     "status": "ok",
     "timestamp": 1602478849820,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "xGcIixswkkEG"
   },
   "outputs": [],
   "source": [
    "def Patch(data,height_index,width_index):\n",
    "    height_slice = slice(height_index, height_index+PATCH_SIZE)\n",
    "    width_slice = slice(width_index, width_index+PATCH_SIZE)\n",
    "    patch = data[height_slice, width_slice, :]\n",
    "    \n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 445826,
     "status": "ok",
     "timestamp": 1602478849821,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "r-HdxMrCkkEJ"
   },
   "outputs": [],
   "source": [
    "# load the original image\n",
    "X, y = loadData(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 445812,
     "status": "ok",
     "timestamp": 1602478849821,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "6GaaBm4BkkEL"
   },
   "outputs": [],
   "source": [
    "height = y.shape[0]\n",
    "width = y.shape[1]\n",
    "PATCH_SIZE = windowSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 470026,
     "status": "ok",
     "timestamp": 1602478874044,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "oumhazm3kkEN"
   },
   "outputs": [],
   "source": [
    "K = 3\n",
    "X,fa = applyFA(X, numComponents=K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 470018,
     "status": "ok",
     "timestamp": 1602478874046,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "tvZuH_0-kkEP"
   },
   "outputs": [],
   "source": [
    "X = padWithZeros(X, PATCH_SIZE//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "4sHtc-12kkER"
   },
   "outputs": [],
   "source": [
    "# calculate the predicted image\n",
    "outputs = np.zeros((height,width))\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        target = int(y[i,j])\n",
    "        if target == 0 :\n",
    "            continue\n",
    "        else :\n",
    "            image_patch=Patch(X,i,j)\n",
    "            X_test_image = image_patch.reshape(1,image_patch.shape[0],image_patch.shape[1], image_patch.shape[2], 1).astype('float32')                                   \n",
    "            prediction = (model.predict(X_test_image))\n",
    "            prediction = np.argmax(prediction, axis=1)\n",
    "            outputs[i][j] = prediction+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "KpnGO-c_kkET"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utkarsh Trehan\\anaconda3\\envs\\MALIS\\lib\\site-packages\\spectral\\graphics\\spypylab.py:27: MatplotlibDeprecationWarning:\n",
      "\n",
      "\n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "\n",
      "C:\\Users\\Utkarsh Trehan\\anaconda3\\envs\\MALIS\\lib\\site-packages\\spectral\\graphics\\spypylab.py:905: MatplotlibDeprecationWarning:\n",
      "\n",
      "Passing parameters norm and vmin/vmax simultaneously is deprecated since 3.3 and will become an error two minor releases later. Please pass vmin/vmax directly to the norm when creating it.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ground_truth = spectral.imshow(classes = y,figsize =(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "5yIVQ8-hkkEW"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMkAAAGfCAYAAAD1ZvZbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA670lEQVR4nO2da4ws6Vnff08Wx1ycsHb22Glsgw0s8dpfkvGRuyQsQhIRDD2KnUiONlEif3D1SjtOIFIiWAuNgnQUxYkUlC/MUbYLhHMBswoQrCmEAScIIbna7GlxW1/iTXDM4okXB8gNcbHz5MP7vt3V1VXdVdVVXZd5f9KenenprqrpqX8/1/d5RVXxeDzF/ImuL8Dj6TteJB7PAbxIPJ4DeJF4PAfwIvF4DuBF4vEcoDWRiMjbROSTIvK8iDzV1nk8nraRNuokIvIQ8J+BbwFeAH4J+Fuq+rHGT+bxtExbluQtwPOq+l9V9Y+ADwBvb+lcHk+rfElLx3018Jup718ApkVPFhFf9gfe3NJxHzR0/AeHnzJ0Pq+qd7IPtiUSyXlsSwgi8gTwREvnb5YiCef9lkecQlpwfVVAVEDggZozJfNqFz6N1P6qB15nfgkUafKtOSX/Le/BtkTyAvDa1PevAT6bfoKqPg08Df22JAqIKKq7f3YxP23kPOL+afidEAUVe9tWOH6wME9UkeJb3h57fS4gCQWJmntf+kBbIvkl4FEReT3wW8DjwN9u6VyNo2qEgbs9cgSy9fz1P9Vw59gcSMwN3cpHhjmXCizD4mcFCzW/7sKIKvc3T/3Cy3DzjGS++bkWvXaAtCISVf2CiPw94EPAQ8APqupzbZyrSRRlzpLz8xWzq3OuL+yHrxirkbUmqoKsP6W1sk5UMzdiS3eVKOj6RMUnmUYKERurs4P5HZdz2XucZC40aGQ7py1Lgqr+FPBTbR2/URSYJ5yfnUM8Wz+8JASig3/rtc2xPnlpRNfxQurBVqyJ2I93FWMtXFxSxa0SdQIpeb6RqKSVOknli+goJnFew/3zGTGznZ/PiLm4jtd/66K3avMBXd2aoIJk7iVVd5M1i9GjDUycS1TkF6WEAVQO9oOFDeCHpZMHqno3++CtFUkSQhTCzb2rvc+LL1cQROYb3RN6rG+G6r9KNnPUaqYLbPap4JPe/o7L+e6PqmLim0FlunJFcut6txSFMOHe2eygQACu7t3gbnwVF2zvIsbrN5/MVa9JZUtbB0KH2oimQ4VMfIWzg9qIQMBYnzYs4qm5PSJRcxOcX50zu1ltxR77iJmRhKnbao8I1P24qlBEd2MZGz80SVH9QlFElWUold2qEicdvExuh7tlfavZzare62cx8UUMrBOp+XWTdUq3RmzCbnxgbt46F7zN3tgDXX8ItMV0wVBik1vobiUhV7MZs9VNfYG4Q2GKC2UyXeaLGm7XziP1rYmKuwTZk9I1P59G7X5GmQ+VVk/RKqMUiSqQhMxWNyZrVdK1KiSesZrdpO7i/DtOVewnf807W3Q3NqklNuNWFYpDtzN1wiYV3AbJvF4dqS+MTCRKSML5/Rmze2fHiyNFzGyrVF106yrH1dF2bqSKB9qkXQsyVy7vLe5Ka5ykBstQWuokaJ9RiESBMIGr2Tk3s/JBeVVmq3KZLvfz+pH3dj/Uwb5Ccf/l1yVc5sr0cJljZ4zW4ZM0wjBVMvzA3bpVbQkjy/X1xeZGLMjcrAP4TANgaVS2xZEp7G09FSkWkru+fRX81IsV3erFaoOg382P4wrc1bpWpxQIwFI2Ltc+a7IOTepYk2xKOFuRF1xVxgi2sAvRWI59Os06XW3GJusTDoxBicS501ezGedX7bpWRdy72gTwhXGJbopodY1k+uZ1Z9vKWBWJw9aDyp51W4/N12by6IHzUonBuFuKaTi8Nzs7wRXtJ56cQRSsvy98CyXl+9d1u9I37T5PZY9LVuI0qTKjueDGi4opptbl6qHTNWB3KwmZJ/RCIABXN/e2PquL/tiCHu9+p2/6ovZ1a2KPyx75TFcRvRWJy8i4YmCZPqtTETNjznL9fVFsoiqb2KQqdq3KXsthpXpsf1Q206UnKY8PRyU9dbeUq9l5bvt658zidRxUJdOlprX38PFtZmtPBzvHW40CfKZrGO5WQgjhsr5AZnGzF5QllSiYb4zJ/rqJMwhFUbGNyNf36L4ukhbpJtPV/Yf0Ifohkjdj6h1XM+5dHdlndcJs181qVirTxV63yS4BXvdZ7ceJrY0s1KkzXcl8GI30vRDJVz7/1Zs2kqZu8rYtCkA8I1ymHyju6Vo7Fu7OU0l15pa7G9ef8i3evFvTT1RatybLUHpvTHohkqPJE8SJLMrNalY501XZrXLZqxLnaYYD5rHps/U81TUOkZy4oJg9d9lMF1DarQIbI+gmVlhny7CSacnlSocKp8h0LcN+u13DE8kp3KiK3MxWuLsq75YyY4cqsL5LdTtQSDcoFpyrCdIpYYHW15uYc/ZXJsMTSZdWYw/bKxVdMK4b36qs6UC3sky5T0mdp63gWlJO5EkyXUBfg5PhiaSnnN/PiFfXy54OknWrDhVBtj50W01BbWRymzNd4xVJF25Zdrlf3lNS/66/coXGCgFsOtN1Cp3c5kzXeEVyarcsnhEui+/WdaUcN0QiFVuYqdblzyWnyXRttavc4kzXeEXSATerGUnuMOqNOPKmrNS5A0+R6QK2lvmeKtPVt176YYikhxmtXOIZUZhpFnT/zxm2nX5i5XUnp8x0ufQ1p8l0Ab1yu4Yhkp5mtPK4uXe1ffPve3JqgohSPbgYa6arb0F8f0QyFGtRgmymq6hKshlBVN8ajDHTZc/SG2vSH5EMyFqUQrcD6z3LQjZf11wTf4qervSJTpHp6pM16Y9IxkROpmv/CKLmMl1tBSddZLrSbl6XeJG0RDbTVf6+6nmm64Q9XclcetGu4kXSFjnuo9p2lZ3Hh5Tpcl9TPtN1tGvWsU68SFpkdTM7XaYr0zvWp0zXMZNX+hCbeJG0iFmCvP0nbi3TJVqmK6YhdG23bkOmy4ukZWb3z7e+P1Wmq02ZpGdtnyzT1WG7ihfJCQhJtr4vm+mqTDbT1aY92d5brlWCRVt725fDi6RtbKtKnSzt3gkrBWxlulrsEBbXuUx7ma5goUwXYNbjdDE/xuBFcgJmNyuSzGadpTJdde6LE2W6AEgZE3MzN8d6FGrrv8RhvqTb098e7p3NQDd7wh/OdMn6Jq/qaaib/miPUHdGcMmz4VZiosdlslxsY7a1Ljslo328JTkV8SzXmuSRznTV3c037XadplvluExX2q3qiTbWeEtyQu6dzYBNI6e7GfI+5Dd2wH7vhtyVRXRrrldb1mQzNR+7h72WtiZry0H+Dl25nChZkMZbkhNTJ9NV96ZIZWrtDdwSNTJdwULtGIByAlE1/3SR5PKW5JS4TNeCcrEJ2xblGGviNNKmNTGeoaT3X90hWKjtLzvsVpljmn3ml3NIEDPh7MTWxIvkxMxuVsSZv7LLdOWtXrTeUr0Inl2RteZ2sUk26AKWqfgr7VZR0rVStQLJcd3MBqmnU4kXSRcstyP4spmu+vfFJp3arruym+lybpWUuK3V/iMoy7mQFLzCrSY4lUy8SDpgdu+MOOMy7M10YZ5b1+VSe0edouRgZWLaSJRKbpVYYRWJw2Gsy+l8Lh+4d0Qi24572Z6uyouygO0tqlvsEE5nCqzlOigQBVETd1SpsWyfq128SDoivYtvOY6repw607XvDDZRBaqFccch1tbkBEIZr0j6Plginu1Yk/3p4IxM6liT9fysdnq6XJxQuKGX/VdUTbZqXs16ZDnVWpNxiKTD/UmOYTW7yV0DUtTTJccZk635WU3ulqVrX9Fmr3LPXc+tOsQpZDIOkQxAEHnEzJCdosKeGyi1evG4TFdzTbWbLFNxgG4rI63tDd92iXF4Ium7G1WR2b2zXb+64CN+y5rUocGeLmc9pCjlcKJVkmZYRLuhyfBEMlCrsY/tfRf3xybpG7zWzZfKdNWZrLKJZ/KvwAXl2ysJ203VuqkqbQlleCIZIeldfKFMYJ5qEa65xHddiS/5erPMxWyGmlcYXGesSCUItu7aEwilJZmMVyRDcsvqZrrq3nc1Ml22F7HgnCZj5QqC9hRbMZTKCYZtt3T48YpkYG7ZUZmuOtakRKbLWQ8tUoey3qErj63tHu1/bQ+NaGOW3XhFMjBiZjnuwuFM11HBt7uBCwRSVDU37praRsP9DZMq2xt4t1nHbMvlGoZIhuQ61WEWczm5yL/jy2S66tx4bohD5hDpmkdeWO7qHWV3rxPdrmW0bU02fV3NMYwGx4G5TqWwwo/PJhBcExdli8S2oeeIJd0G776vRHq9ieveJeWGZc7mGhGrsm3xmr+J807YZJdwfyzJGK1Fwe8UT864vJgQX8QQRKz/nJsU0ZpTZrqy1sO1rqsTyBH39skzXQ0GJ/0RyRitRc7vFE/OIJoSEKUetbfhMjTuQubv21qmSwtLgWzkU961KqKTTJc5UyNH6Y9IxswshlnMdfwkLAKyliMJBbGjVIIw3Bnp2WhPl7U4osUzrdTqo8kVjKfOdDXZ/OhF0jKTywsuVzHxRYybJeXcmGQOLOcE4XaNZBnm+e0lM117XC53cx4c+NaSN3TKKjw4UR4vFdEebJLy8MNfo29961NdX0ajxJMzWEx3Vua5tdvZJbw7TBe7udl9NQn7z3bOyr2u3PLfdIC9vs6mSV+IvYnbanyE1CTIck9/oKp3sw8etCQi8oMi8qKI/HrqsVeIyM+KyKfs/1+e+tl7ReR5EfmkiHxruWsbEdat0iggO2hNMesoDgoE85y8vsfC2MQ+vjYSJdyqrSvLuFc1a5QH2RJx+8aEZXhkUyjl3K0fAt6Weewp4MOq+ijwYfs9IvJG4HHgTfY1VyLyUOWrGmKmaxZzGa+4vrje7m1yn5ah+YNlXat9ZLvo97lTqikXzQXkh8ThKuZ23bySskEtqSS9L/zmRG1znEoO1klU9RdE5HWZh98OfLP9+v3AzwPfbR//gKr+IfAbIvI88BbgI5WuamCZrst4xTS+ttIwWSvnDi/nECRzAsqLY5tMXX1P3ST9nINHdK7blvlw4yhkfZxjU7/5l5cqZAhMURuHNc80Ulgcd+y6xcRXqeoNgKreiMgr7eOvhq0RhS/Yx3YQkSeAJwC+7MteUfMyOmQWM4vh4jrmWkC2UrqmKs1yTm1tYDNdUf497+Z0ybpyftCnMs9bG5v8O1+de0a7Zb/07CwBWDQXmzQ9eLvpintuY0XeE1X1aeBpMIF7w9fRKjNinrRu1dbfQM0ffxkKzKu5VkUsQ4Eo26Vlbt/15JQS98GmWi4lTEP6fO1IZTtt3cw53HRIsn+XI6krks+JyMRakQnwon38BeC1qee9BvjsMRfYN+LLFdfTGNnpCjSfhKbecbw4HEEYbo1F3Zyt5MC6lL+0417lkTOny5yreaFsT2I0g+zqWhPnVrWx109dkXwQeBfwPvv/n0w9/sMi8n3AVwGPAh899iK7ZkbM6jJmEYDEmfvS1TtoxnLkYjNdVcPd2rf11kT6TQzfzh4nzrpR+4KnkTbiVhVxUCQi8iOYIP0REXkB+McYcTwjIu8GPgO8E0BVnxORZ4CPAV8A3qOqX2zn0k/ALGZyccmFmg7d7ahDrUBaFEeKZUhhfJK6ImBT3xA2Wauq7HpDzbtdJnmQ/vSvd5e3PfbUFxPzmMXEZxN0GuWvtUDXbSSnRIPFbllsfTdvZ7xEnH9O7RRVOtO1Tg+0crts7nCtmenKq73WoF4x8VYxi5kR2/b1PIFs6h1dsAxl98Nc2BEIbHq6jrnSLdEdcZyD50kpT6jX0yW0NwhiGOtJTkA8OYOzFfFFlN6Map0VSkIhCI+pdxyPaX7MsyYFBUb7/9rT5Hc6J/ub6Vp3T/cocB8HtrJ/fXG9FaimcfWOLsWRRpI5Gmxf6r6FWS7tW/f2PmmmK7V9XZ1Ml7Skktvrbtm44zrVnesw7RnGtSrVZ3VisguKBA62kChSr80ks+nPOoZvmK0BczWPb6xJ8wK+lZbkMl7BJCbOXVbugvJm6x1NksyFIPOhWWRNXFX+qEyXpDppW8p0mUOn01T1lHJ1fs5Fwxbl9lgSG5RfX18wJTKrZtOosx7dBOVV2LcwqwhjHWtaE9h2seof5iBpa1Jn9eJZPHGFq8YYv0hmMfHkjOuLay7ieGdEjmlEVJK58fdPUfNogtxMV4FUhpTpSmep6mS6gsTMV27S6xq1SC7jFZerGKJgNyOEq3eEuasD+06eNYHiG9i1wde+wTNbS7Vrb7NZtfKERFxPVswlOfzkkoxDJNn1J7OYyWWBWwW4hRRdFASbRJJqC7MEu3d6TV8pPZG+zrDtaidzX1Q7yc29K85vzriZrRq7lHEE7nb9ieuxiqbstJG4ovO6z2rfZuMDQlS3Ss2HMl3uJ7XrJnYkaqsul6asnkCg5dPB8eSMhKDgw7Ee4xAJtjs3uEbiPLcqVe8YhzbW1Ml0qUj9jsXMQLtsirgpqma6TJOjeW7Q9LUMundrFjM5i4myd0kKdf1GPax3NEVuT1dRcXG9L7xSebvr9aE3TYlqTXQbQnH7v0N+T9cmqG/MuuX2bg3WksyIObuY2E+NvLfHpHOXyO5i8ZFRvDBrl82+8MfeUrZ2UrflpdJZ7G9jq/DBwsZWEe4nrbp/wxPJLOZyFRPs3BQW688uT9TC3geCMCRBdvzwopKfHvj5QXIWZrWB6KaQ6a52GilE5FjO9hiGSEoOl8YGeBKGfS2Wt4pzpNbfH+jpGkJsAqzNSXaG2anovUjiyRnJxSo1O3c3bbH2V2+R9cjirEl6YVaZnq5jGkzqVzNKHj+Tru6qF6LXgbsbLr2vRKYw+HpHk2QXirlW/6Ig3qR0698DLiJoelFW6TX8zTKQwD3bvp6X7za9JBvXyrNmOWertF7mHjvKmuhmNyy1gqsrlI2Ou3GriuhVxX1yeUF8NtkaLp3GaqNw0LTHtqvsPFqc6TJfHNuxaNfUH3EIExrl7+zbNb1wtx6TO/oJ/e29gVnpQdMekqioy7kAZ0qOMQHrz7R9Jyp4eTeuVR79XeP+FXye7HDpDabPqvSgaQ/gorXU9wd6uo5aTZVyscr2dDnjpVJmoHe39MKSyJ5tnFRBRl4MbIMkiphmRxAVfMhvVeHrnrCCNVnv7Fv3XO3RX0uyFzF/cE81gjDcuVGLrImpwutxcYndrhoOWJP+CqSQ3otEMD06XijVWWe6LGUzXXVxiQBXn9nKCyA4v2pIAoEBiARooM/odlIr0wWNZrrU5quG/CcchkgwE/o81VnO2VnKWlya5WiXK70wi4GLwzEYkQg+NqlDEIZk52SV2VauNqlM1wj0AQxIJIi3JnVJ5rJlTQ71dJXp+dpH9/nSZhmOSMBnumrirEn65t2X6UK02NIcosbqJ03910cGJRLBLNP0QqnBcs52tFCCstZk3dYiOyObDr8WO+5It6c49ohBiQSGmEDsD7uD9/Zkutx+jCVa7QUqicP14K1bYdZBTD+FMjiRgI9NjqGRTFfKcqTK7IfPbf+RrDi2LqjFxVs1GaRIfKarHnUyXVs/c+KQapbDvPaAOHaf3hv6t56kDAJTBZZdX8gAWc5Jj+o6mMlyVfQaed11Y3HVGat2P3ntiXM9SEsC+EzXEew0Mh6qm7g+9rpuVd3r7Ik5GaxITKbLC6UWmUxXFrFultsTvU23ai89ieIHKxLYpIQ91SnKdDk3p4o4NP1PE+LoGYMWCZgln96a1GNnKVG1ZFVjbtVeemBNBi8S365Sj7xMV2du1SE6FsrwRYJPCdfGZrrK0rVb1ZVORiESxC/MqkoSRcYEVzAfrbpVJU7elUEZh0jAL8yqSLAwxZJK79oxwyKaoKNq/HhEgs90VaPuZBQ6F8qp/8qjEonPdB0miSI0qOZm7dCxUE5tTYbZllKEb1fZixkz1FCzhxNKVzGKcrKlj6OyJOAzXftoTCCOriyKy6ydSJ+jE4nPdOWTv2VcUwfvyPU6UXwyPpGAz3RlSKKoPc+k47f6FN7eOEWCz3Q5zPDslh34LgP5E7hdoxWJz3SdSCAOJ5SOxNKmTkYrEuR2W5OTCsTRlevVcpFxpCJRs8nmLd0mrhOBOLrMeLUklHGJRAE1+7ffVoFs6LIqTnoDktO6YS0Ipff7kxxEQcXuvgu3fou43H1J+kL6r9yWf2Sn2df8/QeysWgJNi3bZiC0sRq3Wxxg3awF+Zux9oH1pPkWRZzaX765Qw7Mkrg922+7xcjShgXZ+uBv8Ljrg7cZbdcTSq4l6b1I3HupbLZM9ALJoWGFuD/Iei/E9Aiiho6/bxjF8Se4JSLxO+6WZLrYu3NxWbLCyH3OgZNUWR/fqkigjlCGtGei4nfcLcl0UX3xVAZldyxvEe45ef+5Y5VhPRSvzaxXQ71dPRWJz1SVwgrkGMpYj7JUFcpJGgEaKJ/0VCQAvq1kL9bFqoOzHG3Mc6jcxd528bGBtfH9FUkvE/39IImiWnNyq7hVx1JZKLToeh3ZttIPkbz5zbkPB36eVi51vKxTiSNN5U/wNq3KEeakFyJ5w397kP8LiFks5DEkUYROo9ICybpVXdA7odSgFyL5xCOPFL+RXU7m6BFJFFWyIF1YjiJ6JZQa78dBkYjIa0XkP4nIx0XkORH5Tvv4K0TkZ0XkU/b/L0+95r0i8ryIfFJEvrXMhcgyLDImPoCnmovV5Qy5ImRt1sq+gHaEUsPtKmNJvgD8Q1V9DAiA94jIG4GngA+r6qPAh+332J89DrwJeBtwJSIPlbucnKv3a9bN7z5ggWzRk8xXlbfooEhU9UZVV/br/w18HHg18Hbg/fZp7wfeYb9+O/ABVf1DVf0N4HngLWUuZhkW1GBv8Zp1tzakzDvQe4FYaqWImxRLxbRwpZhERF4H/AXMZKtXqeoNGCEBr7RPezXwm6mXvWAfyx7rCRF5VkSe5ff+AHDFw/xLv42rDKssnhqKQBxVhaJNW5UKaeHSIhGRlwE/BvwDVf1f+56a89jO5ajq06p6V1Xv8vCXrh9fhpLvdd2yAH7MAnFUEcpaIw3fB2XOX0okIvISjED+nar+uH34cyIysT+fAC/ax18AXpt6+WuAz5a6Yow1ybtwldsVwI9dII4+COUQZbJbAvwA8HFV/b7Ujz4IvMt+/S7gJ1OPPy4iLxWR1wOPAh+tclF5mS7hFm3WM11QJgoZukAcJxeKinl/SzYJl7Ek3wj8XeAvi8gv2/++HXgf8C0i8ingW+z3qOpzwDPAx4CfBt6jql+s8ZvsPnQLlJJEUSNt70PDpYjLiKWWUGzwX0UcjoPLd1X1Fyk+5l8peM0/Af5JhevYYRkKmsl8uvdlGUaj7BCusrpwLFYki2i5ZSDuXljHqgcWwbhj1vnw6UXFPY+iTNdoP2Oni1svEEdZ9+tgX2RNy5GltyKB4kxXMLJ0cBUXa+wCcVSOU5xajnCriui1SIoyXWPr5woW4yoWNkWdgF6tT9XkHdJrkUB+pktHFMCbXaduTyarKlUD+jY+PnsvEgDJDKtw5nXIdRO3+20ZJ+u2CiRLV2/BIESSzHd7usQ2Pg4Vt/vtIbxADJXXzzfIIERS2NM14Cp82fXp44q+6tP03K8qDEIkUJTpGt4ttF5dWOE1I8tTVMIF423FG2UYjEiKMl1DWt1bdXWho4N2pc7pgzgcgxEJFK9eHAIaLMy6kK7/4gOgL+JwDG6qvGgm4BVQFr3ajyQbJ5lK+vGxU5fbprdNOuboizgcgxNJMhem7PZ0JdHp+7lMr1XeXdv8brcm7T1OugzKy9CPgdmP3VF+6B2ln5+7J7lqa3ODNwug8jjdn3Zs6eCGtxFpgvFs4rMMBRZsvcMqwjKsNz847R4FCy1Iz3b/59x0vnZ9JcfRd8uRZZAiMZmuaNflqnOw6YJpeuBbdNo+Y3e/D+WGOZYeWo+DDCq7lSYv01W5ncvt69HBX63qGKqh00bj4akYrEggv6frUAU+iSJT0Asijt3Xoy7HiGNoNZMhi8MxSHfLsZPpEpgqZuBR3vO73N+cZi1H32OTocUd+xi0Jcnt6Sro59Kp3Zm2gz9b065V32+8vhUDj2XQIoHdni5heyzq1iT2E//V2ow7+nYDtrXgqQ8Msk6SpahuorQXlDf9rtW6zO7/dMAwM1YFDGlj0WpIMs9Zvdi8QJR+ZaW6DODHbDmyjEIkkJ/paoK+CSNLF0IZU1BehkFnt9bYiYfH/NG6FEHd6z51P9dtE4djsCJxgXmwAJX6DYVdiaOpG+0UrSpjy1ZVZXDulhugEERKEHGUT9yFQMrebGr/SQhJ6GYdTXrh021mWNkt51Yd8VcbglulatpuwtQalEVQ7FC20R18S12rYXYB3ya3ynX7LyUkTLYLokuKlwE05XL1eeFTl/RWJEkUESyUILA98eW3Ddyh9wJRSCRkKRAlEYT5/WdtNtR4t6qYfrpbt8Wtsv/MJYEkOPj8MMLEYXuOV8eaeIGs6W8x8Q2f//y6O5dpdFQhsMuaRiU3RRVJQuZLygkkaHZp8m0qBh5LPyyJNBN29t16OMuxFHPDR8nh4RBhEBIkoMHheKyMJbmlAXlZci3J4EXS9dVXiTvCkm6VI5oq6004Kpyn8EfeahximNmtIgYjDoAkJJSwklsV6PYUOwUkMT/bZ1WyWa5024oXSD16EZNUpWu3qtTNpoCqKQYGlLMgQQJhREC0EYhCEsI8wdRNopDd8eHb1+eE4VO6zTAYS9K15YDy4lBRljInSoSoxHSKMAiZskBUiFInUZT5UghISM+2S5hzSHLetWqO3ouka3HUcavmSblXrV0rNx9p/TIlZMk8EaIclUVJhO6pwHtxNEuvA/eur6xKUM7SuFVlMlYAEeHOYjGzPD8kSqJccaRJCPbWTDy16G92666IPtv1RWQoldJVEJRwWeGzO0hY2PEVW69SJZQlUclySBhBpIE3G80yruxWG1S1HEuBsKJrNSXYOo+izFnCUojC8uP1orDdNhXPBi8SqtxoCsmcxPZYlQ3KTcYqM5cVJUyEOTbuKHOwDPOlF8opuPXuVpU2kkpulcUUBDP1DlUSmTczBX8xxW960hj97d06NUL52oEqhCQkUn5ifRiERIQsArZu4CQ0gTnzZWPbRFS5Lk89bp27VbbHSlAS5iwFSIJSW/A412pKBFsxtZKEQhSarFZThJH9x2e5WuXWuFvl29cVSeZbqwLLEAZhbtyxFkeNmKPwXGHAIjBS9o5Wo9zOFHClm8jGCmVrHek+K00N31ZgjmlmbEocYWhq7F4crXL7UsCl20iw7esVBGL6rGxBb2tZsZqltk0KJIIQs+CqsLXRp7laY5SWpFLGSpaV2tcBCJKdQp5z00pXA0sQhgELOzZ/3++UhOa0C19bPJbxZ7fKZKzMwic1g3qWUlogYRAacQTKIhWVm5WQavq1GhJIGAZoNDU3fYFAFCOOMIHVzYwoSkzmzNM4o7EkZdO5VVYFOor6rFBT0INmA/O9i9ltl7GE5sRXN/fWP1pdxkQVjaJni9sXk2QpO3AhjRFIRHof9iSEeZQQtVCiCMOAKFBy87pJSLiMuD875+qm+XN78hmFu1UuQNfKaV2CBDKrAJ3/32DosYXJmOX8RgpEIWf3ZoWvjaKExHtcjTN4S1K6OLiskLnCLYSa7sgqCFtUCOSc0V7PEs5SrlUeVzf3YNLGVd1uBmtJqo3vobQVCYPQFAY1Z2MgtHIirNQ5w4AwAl0E+UG6lot5LiaXzV+cZ3giqSIOBUjCdbB+kCAhSOyneaZp0AXqTfVcgRFHEkVEU4gItk7pzhcmIPNkK0DPcjG5ZHUZw8IvxGqDQWW3KrW0K6W7dp3lyC1I2GLjfNlOa0le7dytMTmb7XevAC4uJ5s9IT3HMtzsVuWh0zInWpYb/AZ2jXnOXZaEEElCWUN08Hy2tSSMIAg0t3qehCAsD1qOMIKFBlykdO3aYaLtjbs9R9JrS1LFrRI7dBoO10DWrexMdz7J1f7rhjk0ZT2SKLLn3I073Dnzah9ZVpexKWqm56XYwXdns3vEM7h+MvaWpR7DanAsLZCcvTwOUVyrM6sFGy0MYifk73QIbwtyX2oXjPVICAi2DmN8wavzc+LUy+Ozyf7J2p4i+i+Syh9+Fbp2nfWImO7sr+imIyZBc4F5umtXcoZgJSEQhaxmxVVBl60yk1GyHYwK4ZLZ2a7VmcXwZBx7h6s6/Y5JKmWstHzXrhs4HaU+ydMfxCxD5nYyYlOD29cbD7mu3cy9ncwhIOHqQGBuLJBzrDbNYuESzu6dE581c72e/fTCkpQZmL12TajWtZufQUqlrBomjMiNO9Ln3BdzgIk7QrMLRSooN7/7zdXhjJe3JLXptyXZiyqynBOW/LM768E0yskgmWW5wbzZegdgO4R3JRmSQCKcnRfHHc610miKXEuqUdFc7/3ZOTf7wxbACMTTLP0WifWtqqwWJEiYErAzLNdmv6JECJpcLRgkLCJnrbID58w5gxCu9gTmZ/GExC7gEgDZrLO/mp1zIKYHjDhWlzFnK+PmXaSuwc8FPo5+ultu6DTVltK6odNtL4ZyFI0adRuErkp89K/iy133zCYk7pVs9Z2cxTsZOzddMpG5sao+21WGeu6WiHwp8AvAS+3z/72q/mMReQXwo8DrgE8Df1NVf9e+5r3Au4EvAt+hqh8qfZkVhk6n15hHKiDRVlTuhk7XGfxWeE5rPSINCHJCnVASZL6/1rHusYoymTYrjtX5OfeuDl/LLIYnr03sseWehcJcEpI9O/Z6ynPQkoiIAF+hqv9HRF4C/CLwncDfAH5HVd8nIk8BL1fV7xaRNwI/ArwF+Crg54BvUNUv7jmH1h06nf2ErDJ0uipJFBHo7jbA7pxBGB4URxJFTDXbRmLcKmCr3lHELDYuWvo4Lo0dBrs1o6LCqWeH4+skIvLlGJE8Cfxr4JtV9UZEJsDPq+qfs1YEVf2n9jUfAr5XVT9SeNy7dzX8/gflfxU7dHrnj15x6HRZwjAo3prNnvNQn9UqviTSzLTFVDo4r96Rx+Ri9zjOpdyX9JvmphQ8Gepnt0TkIeAB8PXA96vqUkRepao3AFYor7RPfzWQ/gh/wT5WyCP/t5xA3Gyr3WJgvaHTe8+V7rOastsVbGs1wXy/QJz1eJJga4Met8rw3tmMGfsFMouti2bdM3ccF/sso/0CAcz74yeq1KKqJXkY+Ang7wO/qKoPp372u6r6chH5fuAjqvpv7eM/APyUqv5Y5lhPAE8AvOzP8ubH/0Pxedcp3VRPhsv+hA33WK3PGbHdH+VQzN5sHI47drZHsNm6q/PyrlW8ujTrTLLFdjHXUKUdJ681xrPF8XUSVf09Efl54G3A50RkknK3XrRPewF4beplrwE+m3Osp4GnAe48VlxMDCOYruOAyL2YuSwhXDYvjtR0xPTt5wZdh0s5uELwbBKjixiJ2C7vz5fMzs5LiQPgchVzvYi34g4wv3vlpcjrX6L6y247ZQL3O8AfW4F8GfAzwD8D/iLwP1KB+ytU9btE5E3AD7MJ3D8MPLovcL/zmOg7fmj7MbPGI9rN8ScmMG16bQcc32eVF9ing/oycccsdvFLZoiW9a2OWRlpetf8OJU91LYkE+D9Ni75E8AzqnotIh8BnhGRdwOfAd4JoKrPicgzwMeALwDv2SeQLFtDp939ausmJi3cvEBcjSHbZ6VqVgUGsLfPanUZEwaXdtfc9ashmXP/3g1wc1Ag8cpmvogQYnMc93uzBGloqpa3JpXpRTHRWZJsBqnxvTwymD6rvNSoqTUEHF42a/YH2Vyze+3qZlbarVrXOzJp4ZCabtUefGFxL/1tlX9M7ugn9LfJ7uVhOnObFUe6zyqv9TG0g66L1ndsta/vxMHF7etZXI/V2STeOs6+ekcTeJHspb8iSbelrEeG0kLGqnBd+cZywIGVgfHljl+vdpLj2b1y1mNylrO60K3LF9OZ3IZAwBcWD9B3kbSzl4cjIWCas5TdxR1l2tez2x5UaV8HW++4vmZ74MRGHG0JI4svLBbS31b5N/AIb3XduQ3eJ2EY2MbHaCuDDKw7dGVe3EpyMbnMTHbfyCNMhPv3yrevn01igmt2Ku6hLAnltO6PLyxWox+W5M5jSjYHfCSF68rVzASOwv1u1Vk8MbvmZoSlwP3z8kH55cXEjCvKVgOTeWtxRxl8YTGXHrtbDYtEo2l2oS5gkgGHMlaQ377uEglV2td33DPbRtLmmNRDuM6F/Ilft57+ultNkESRqa9kmnTTWyQEUbFAnGsVTUEldmUKxEblq5t7xAcE4nqs1O6ms71VwxGV8gZYD8EIBCneL8uTwygsSd668rQ4ogPiIIxypiDWaF+fxNsLn7D9ZbSbsdpHRGi7hsG7VwcZl7u1biXJ2S4tsRmyMu3rC92dwSt2f4UqbSQ7adUG2kiOJoxyRhF59jCO7eDckOlFoDvbpSmbuONQ+/pZPNkaUu2Ga0uYMFsdbiOZxaaV5OI6NsdxXQL2IkJZdiaQiDCVdPACOZbBWZLcdeW2x0nCwzN0d2b1AKgyu39e6vyzuGBIdWpdflesXausafWUZbiB+3oqScY1Ag5ukZZuIyG6ZntTQRMvnJ0fbl9Pt5GQWSIidnViVwJxVfQAdqulnqPptUhcMTBYAJmVfesW9Cjk7KY467TprIV04+Q8sVMQZ3BoVFW8uuQyTh9nI465LEmkO+sRJKCBbzNpk966W0V9VmXH9bgpiNvZJrMWfLYqV+twrlXWPVO6davAicO3lzRM/92tvft32Gkqh9pIIG8Kormx78/Oma0OX8c6nRsrxNnAA1vv6IbInXkaZNZOetqiNyJZxx3resfGNVoSEqzFkS+Q1WVMEsW5UxAJl9y/KRd3pKcgbq1rSULC4PR9Vo7IjkmyUyl8YH5CeuFuPSZ39BP8Njt9VpTbFq2tKYjp43SN79w9CT0uJt4VJTVVqEwTYtEURBcvrGY3pTNWT8bXu+NRe9BnFREShnmLuzwt0WORuEVXJcb1FE5BTI3rGXIbicME5r7H6sT0VyRmp6vD26IVTUHcjOs5Ygqigtgxq12yXjnoR8F3QX9F8pjc0e+YTQt/vrYe2e5VO17oZnXYdGSnIOa1wXeFy1h5cXROf0XyNQ8/rE+99a07jxfNskLLT0F0GatFngFy41Hp1rXaWdzl6YphiSS3P6rGuJ7L1W7cgU0MdCoMfEGwh/S/mLi2HCwgzrhEhAThkntn5Vyrs3hCwIL0zoGu3pFIt5YjuwDK0296Y0n+6of+Z/6YnWTO1T1T6zhkPbanIG4fBvSkE0nyWKd0/RqPvtJfd0vu3lUebO/k7tpIqrhVuyODzN5A8xYmIVYmjHJHGnl6RY9FsrVnotlttkoxMK/esbSrE7sWh7Me2SUsnl7Sd5GYWVbHTUFkrZAux/WAF8dA6a9I7shjOr36ulLPzZ+CyNZus13jAnMvj8HR3+zWH3/1DbBfJPumICZzOt9tNl0QnPqc1ajohUgOcXmRmqboNrvCtq9LiPvs7oogAaamWunFMT564W49/DUP61uf2q24T85ioqmisruR6KHdZk+FEYgPPEZCf92tNOv29Wuz21OUGRMqy5B50N24Hti4VpuCoGfM9EokabfqItMGH0rCXCAh5XN1QHZ/Dy+Q8dMbd+udn/lQ/qhS24TYdb0D8AXB8dPfFLDcFdUH2Z3VejAm1GKsR+CtxvjpcUziBNLGbrNH4CYiZhMHnttFPyyJq7j3xa3CDV4AH3XcKnpsSd7wCOEnuhfI1gpBLw6PpRciecMnOl4ZiC8IeorphUi6JCJkoTY70NHgOU+/Gdz+JE0RERIkpiAogg89PIXcTpGEEQumdlyjV4dnP7dKJG4HKNNq5cXhKcetEIlzrRZ2lywvD08VRh+4rxdABb5i7qnHKEWSrncEfiKi50hG6W6FYbDZEdcLxHMkoxJJkJh2Ej8y1NMkg3e31q6VBhjPyivE0yyDFkl6AVTk3SpPSwzX3Qojs6+7Dzo8LTM4S2LWeFjXyntWnhMwGEviquULAr/5rOekDMKSBLowk1NqWg63J0n7a9P9tPgx0luRpAuCte5uXf/Dci5EkkB2v8XGUHcqr5ER0kuRBAkkkemzKmM8FBB7n8rSroxfQhiYrd4iEvvYvNnPeje+njmhhERJZGaDeaGMil6scX9M7ugP8Q6g+kREt996FCWlnt/E0lw3nDuU5c7P/OCIQZO7xr0XgfvnecR06rJAS7bpqppdc2UZlhYIgCTzjWtUGV2fM08gAKEske4/dzwN0gtLclfu6gMeHHyec6uwLlUY1Bs6tNCgtEtU55xREuF7YwZJf6ellBXIMjTjTo/FxC2Hb+J9btVhfKZrLPTC3TqEouvt3Zo76D4Letit2kcYhEe4dJ6+0Qt3a3vPREsmW1XXtSoiSiI02OzS25Qrt3X8nX3oPT2nx7OAsyJJ7XvYJi7TdZxbVYzPdA2O/ma30iQhJxEImEzXMW7VIXymaxyUtiQi8hDwLPBbqnouIq8AfhR4HfBp4G+q6u/a574XeDfwReA7VPVDe499V1QfmN2roHnXqkt8pmtQHJ3d+k7g48Cftt8/BXxYVd8nIk/Z779bRN4IPA68Cfgq4OdE5BtU9YtFB37kwRvMHiQjEsc2PtM1ZEq5WyLyGmDGdt707cD77dfvB1syN49/QFX/UFV/A3geeEsjVztAfKZr+JSNSf4l8F3A/0s99ipVvQGw/3+lffzVwG+mnveCfez2spzvzzh7es1BkYjIOfCiqh6u+NmX5Dy2c4uIyBMi8qyIPPsH/F7JQw+TMAhZHtMN4+mUMpbkG4G/JiKfBj4A/GUR+bfA50RkAmD//6J9/gvAa1Ovfw3w2exBVfVpVb2rqnf/z5v/uwlwR0wUJT7TNVAOikRV36uqr1HV12EC8v+oqn8H+CDwLvu0dwE/ab/+IPC4iLxURF4PPAp8dO9JHgDTaPRCcYVKz7A4pnfrfcAzIvJu4DPAOwFU9TkReQb4GPAF4D37MltrBNAF0Hy9ok/49SbDo1cVdwUkOU0hsSui1lZHehqg/xV3ATSICMMe7EvdEqEsfaZrYPRKJGCEMo0YtVB8pmtY9E4kYIQSLHS0gbzPdA2LXooEMH77dNH1VbSHz3QNhv6KBMx20TodrUXxsckw6LdIYG1RxiaUMAgRH5kMgv6LBEabMvWZrmEwDJEAOtKKvM909Z/BiERknELxma7+MxiRwHiF4jNd/WZQIoHRhic+NukxgxMJMLqOYZ/p6jfDFIntXRmVUGSJD+H7yTBFAqMUShJ6e9JHhisSAIGk7vZXPSSKEu929ZBhi4QRdgzb2WOe/jB4kaRb68fievlMV78YvEjAttaPQx/rTJfXSX8YhUgcGoyjtT6UpY9NesSoRCIIC8bRWu8zXf1hVCIBIxQNht9a7zNd/WF0IgGO3l23N/hMVy8YpUgAGIE1AZ/p6gPjFQkyeKH4TFc/GLFIYBRC8ZmuzumFSN7AIy0efQTxSTL3MumQXojk5iu/nISwvRthOuypkL6Vvlt6IZKvf8nvc292xpKWVugZr2vQbpfPdHVHL0QCcD1ZcW921t7npZg5w0MWig/hu6E3IgEjlPuzWWtrjwSMSRkgYRCy9FX4TuiVSACenExgnrQmFMVMhRwivgrfDb0TCYASMbs/a+V2EACR4QbyPtN1cnopEoDr1aRV1yuIGKRF8Zmu09NbkYBxva7O2xMKMtCMl890nZReiwSMUNpyvRhwx7DPdJ2O3osE2nW9XGv9kPCZrtMyCJHAxvVqJ5g3i7WGhM90nY7BiARserjFGsrg3C4fm5yEQYkE4Pz8qqU1FsPrGA6D0K83OQGDE8n1ZMX5/ZkXimXpjUnrDE4kYAJ5aW27AkGnwxFJEIY+09UyvRDJ83/85ZVfoxGQtCMUYThTIX2mq316IZKvf8nv13rdbHXT8JVYxEyFHIrb5TNd7dILkdQmnhG21AspmNb6oVgUn+lqj0GL5HqyYhGFrTUNm/Gpw/mE9pmudhi0SByLKGxxc07TWt931ysMQp/paolRiARgdr/NRkiBab9bV8IwYDogqzckRiOS65XtGG6tJN/PxVpRErHQgGk0osmVPWM0IoF221aAXrXWO3FoECEyisFJveVLur6Appmd3+cabelTVdApSGJigK6IdIoSjHa77r4xKksCtm3l6ry144vQWUU+DAMWGoCIF8gJGZ0lASCeQTJpbfsrEVANkGXYukVZu3fTiIWA9MPbu1WMzpKAsSaze2etta2AEUrbGa8oiYzVCiLwcUdnjFIkYISiEe0G8khrgXykUwgW3q3qAaMVyZp50t6x7da/TQklSkwbzILAmiqvkD4wepHMblYkbc0YhsaEEiURTCPnWXl6xOhFcj1ZsZrd0KrfdWR8stAAWw309JDRiwTsWKKr81Z1olItPomSiEinLFy9wwukt9wKkYBpW5ndn7V2/LKt9VESsWCKBpGpd7R2RZ6muDUiAUz9pMV+chueFArFxR3iu6wGxTiLiQVcT1acn98nVqWt3KoALBTCOWEQrl0wdcXAVs7qaZNbJRLYCOWaFm9YU5InDIVFoN5yDJxbJxLHnARocWmuCFN8+/oYuF0xieV6suJmtmq1bQW8azUWeiOS85uzk57verKCKGy5bcUzBnojkuvJ6uTnVKJ221Y8o6CUSETk0yLyayLyyyLyrH3sFSLysyLyKfv/l6ee/14ReV5EPiki39rWxTfB7GYFoReKp5gqluQvqeqfV9W79vungA+r6qPAh+33iMgbgceBNwFvA65E5KEGr7lRricrZmf38H6Xp4hj3K23A++3X78feEfq8Q+o6h+q6m8AzwNvOeI87RPPCFl2fRWenlI2BazAz4iIAv9KVZ8GXqWqNwCqeiMir7TPfTWQ9l9esI9tISJPAE8AfPXLXlbz8o/j/OyGWQzx9YVPRXkKKSuSb1TVz1oh/KyIfGLPc/Nutx1fxgrtaYC7d+6c1Nc5vzljEp9xzdTUMbxAPHsoJRJV/az9/4si8hMY9+lzIjKxVmQCvGif/gLw2tTLXwN8tsFrrs35zRmTywuup6Yo7peLe8pwMCYRka8QkT/lvgb+KvDrwAeBd9mnvQv4Sfv1B4HHReSlIvJ64FHgo01feFXOz26Iry+IgtbatjwjpYwleRXwE2LurC8BflhVf1pEfgl4RkTeDXwGeCeAqj4nIs8AHwO+ALxHVb/YytWX4PzmjPhyBcE1XHh1eKoj2oNR5Hfv3NFn3/GOxo7nqvdGHAt80OEpyYNUiWPN6Boc79/cMLk0bhUx+MjDcyyjEcmWWxV7y+Fpjl64WyJ3FZ5t4kgNHMNzi8l1t3oiEvlt4P8Cn+/6WjI8gr+mMozlmr5GVe9kH+yFSABE5Nk8FXeJv6ZyjP2aetMq7/H0FS8Sj+cAfRLJ011fQA7+msox6mvqTUzi8fSVPlkSj6eXdC4SEXmbXeb7vIg81eF1VFqi3OJ1/KCIvCgiv556rNOl0gXX9L0i8lv2/fplEfn2E1/Ta0XkP4nIx0XkORH5Tvt48++Vqnb2H/AQ8F+ArwX+JPArwBs7upZPA49kHvvnwFP266eAf3aC6/gm4Az49UPXAbzRvmcvBV5v38uHTnRN3wv8o5znnuqaJsCZ/fpPAf/Znrvx96prS/IW4HlV/a+q+kfABzDLf/tC0RLl1lDVXwB+p+R1nGSpdME1FXGqa7pR1ZX9+n8DH8esgG38vepaJK8GfjP1fe5S3xPhlig/sEuLIbNEGXhl4avbpeg6un7//p6I/Kp1x5xbc/JrEpHXAX8BWNLCe9W1SEot9T0R36iqZ8C3Ae8RkW/q6Dqq0OX7dx/4OuDPAzfAv+jimkTkZcCPAf9AVf/XvqfmPFbquroWSW+W+mpqiTKwtUQZILNE+dQUXUdn75+qfk5Vv6iq/w9YsHFdTnZNIvISjED+nar+uH248feqa5H8EvCoiLxeRP4kZl7XB099ETWWKJ+a3i2Vdjei5a9j3q+TXZOYpbI/AHxcVb8v9aPm36u2szUlshTfjslM/Bfgezq6hq/FZD5+BXjOXQfwZzCD9z5l//+KE1zLj2Dclz/GfPq9e991AN9j37tPAt92wmv6N8CvAb9qb8DJia/prRh36VeBX7b/fXsb75WvuHs8B+ja3fJ4eo8XicdzAC8Sj+cAXiQezwG8SDyeA3iReDwH8CLxeA7gReLxHOD/A3JKga1AyGRAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_image = spectral.imshow(classes = outputs.astype(int),figsize =(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "vBPvnosekkEZ"
   },
   "outputs": [],
   "source": [
    "spectral.save_rgb(\"predictions.jpg\", outputs.astype(int), colors=spectral.spy_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JL4rV6j7kkEa"
   },
   "source": [
    "spectral.save_rgb(str(dataset)+\"_ground_truth.jpg\", y, colors=spectral.spy_colors)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN/aVtrq8w9XQ9tKxeZX/5h",
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
